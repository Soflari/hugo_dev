<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Soflari</title>
        <link>http://localhost:1313/hugo_dev/</link>
        <description>Recent content on Soflari</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>Soflari</copyright>
        <lastBuildDate>Mon, 01 Dec 2025 22:40:55 +0800</lastBuildDate><atom:link href="http://localhost:1313/hugo_dev/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Mainpage</title>
        <link>http://localhost:1313/hugo_dev/p/mainpage/</link>
        <pubDate>Mon, 01 Dec 2025 22:40:55 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/mainpage/</guid>
        <description>&lt;h2 id=&#34;mlpcnnattention的张量表示和梯度推导&#34;&gt;MLP、CNN、Attention的张量表示和梯度推导
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/mlp%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MLP的张量表示及梯度推导&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CNN的张量表示及梯度推导&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;注意力的张量表示及梯度推导&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;机器学习笔记&#34;&gt;机器学习笔记
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E7%AC%94%E8%AE%B0/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;深度学习理论笔记（未完）&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;扩散模型笔记&#34;&gt;扩散模型笔记
&lt;/h2&gt;&lt;h2 id=&#34;hugo博客相关&#34;&gt;Hugo博客相关
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo博客搭建&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://soflari.github.io/hugo_dev/p/hugo%E5%8D%9A%E5%AE%A2%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%97%AE%E9%A2%98/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo博客的数学公式问题&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>卷积模块的张量表示及梯度推导</title>
        <link>http://localhost:1313/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/</link>
        <pubDate>Mon, 17 Nov 2025 14:19:08 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/</guid>
        <description>&lt;h2 id=&#34;一维卷积&#34;&gt;一维卷积
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Pytorch的定义&lt;/strong&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/pics/Pasted_image_20251113124916.png&#34;
	width=&#34;1110&#34;
	height=&#34;557&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/pics/Pasted_image_20251113124916_hu15768630928441355763.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/pics/Pasted_image_20251113124916_hu10844074300712331657.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pytorch卷积定义&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;478px&#34;
	
&gt;&lt;/p&gt;
$$\operatorname{out}(N_i,C_{\operatorname{out}_j})=\operatorname{bias}(C_{\operatorname{out}_j})+\sum_{k=0}^{C_{in}-1}\operatorname{weight}(C_{\operatorname{out}_j},k)\star\operatorname{input}(N_i,k)$$
&lt;p&gt;
写成数学形式：
&lt;/p&gt;
$$
y_{ni}=\sum_jv_{n(i+j)}w_{nj}
$$
&lt;p&gt;
偏置被放进求和号作为输入和卷积核的一部分。
将批次忽略，也就是只看某个样本卷积操作的公式就有：
&lt;/p&gt;
$$
y_i=\sum_jv_{i+j}w_j
$$
&lt;p&gt;&lt;strong&gt;定义张量和索引：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$n$: Batch (批次) 索引 (对应 $N_i$)&lt;/li&gt;
&lt;li&gt;$j$: 输出通道索引 (对应 $C_{out, j}$)&lt;/li&gt;
&lt;li&gt;$k$: 输入通道索引 (对应 $k$)&lt;/li&gt;
&lt;li&gt;$i$: 输出&lt;strong&gt;空间&lt;/strong&gt;索引 (对应 $i_{\bar{y}}$)&lt;/li&gt;
&lt;li&gt;$l$: 输入&lt;strong&gt;空间&lt;/strong&gt;索引 (对应 $l_{\bar{x}}$)&lt;/li&gt;
&lt;li&gt;$p$: 核 (kernel) &lt;strong&gt;空间&lt;/strong&gt;索引 (对应 $j_{\bar{k}}$)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;现在定义参与运算的张量：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;输出 $O$:&lt;/strong&gt; $O_{nji}$ (Batch, Out-Channel, Out-Spatial)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入 $I$:&lt;/strong&gt; $I_{nkl}$ (Batch, In-Channel, In-Spatial)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;权重 $W$:&lt;/strong&gt; $W_{jkp}$ (Out-Channel, In-Channel, Kernel-Spatial)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;偏差 $B$:&lt;/strong&gt; $B_{j}$ (Out-Channel)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;卷积张量 $C$:&lt;/strong&gt; $C_{ilp}$ (Out-Spatial, In-Spatial, Kernel-Spatial)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;定义卷积张量 $C$ :&lt;/strong&gt;
这个 $C$ 张量定义了卷积操作本身
&lt;/p&gt;
$$C_{ijl}=
\begin{cases}
1, &amp; \mathrm{if} \quad l=i+j \\
0, &amp; \mathrm{else} &amp; 
\end{cases}$$
&lt;p&gt;
卷积操作的张量计算公式：
&lt;/p&gt;
$$y_i=C_{ijl}v_lw_j$$
&lt;p&gt;
这里的 $v$ 表示输入数据，下标 $l$ 表示 $v$ 的第 $l$ 个分量。$w_{j}$ 表示卷积核的第 $j$ 个分量。$C_{ijl}$ 则表示卷积操作，将约束条件带入上式，就可得到
&lt;/p&gt;
$$
y_i=v_{i+j}w_j
$$
&lt;p&gt;
扩&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加入步幅 $s$ 和膨胀 $d$ ：&lt;/strong&gt;
此时卷积操作加入了步幅长度 $s$ 和膨胀大小 $d$ ：
&lt;/p&gt;
$$C_{ilp} = \begin{cases} 1, &amp; \text{if } l = s \cdot i + d \cdot p \\ 0, &amp; \text{else} \end{cases}$$
&lt;p&gt;
让我们通过一个简单的例子（$d=1, s=2$ vs $s=1, d=2$）来理解。
&lt;strong&gt;Stride (步幅) 的效果: $s=2, d=1$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式变为：&lt;/strong&gt; $l = 2 \cdot i + j$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;它在做什么：&lt;/strong&gt; 缩放&lt;strong&gt;输出索引 $i$&lt;/strong&gt;。索引 $i$ 代表你正在计算&lt;strong&gt;第几个&lt;/strong&gt;输出点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;我们来计算几个输出点：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_0$ (即 $i=0$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 2 \cdot 0 + j = j$。&lt;/li&gt;
&lt;li&gt;$y_0 = \sum_j v_{j} \cdot w_j = v_0w_0 + v_1w_1 + v_2w_2 + \dots$&lt;/li&gt;
&lt;li&gt;（核从输入的第 0 个位置开始）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_1$ (即 $i=1$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 2 \cdot 1 + j = 2 + j$。&lt;/li&gt;
&lt;li&gt;$y_1 = \sum_j v_{2+j} \cdot w_j = v_2w_0 + v_3w_1 + v_4w_2 + \dots$&lt;/li&gt;
&lt;li&gt;（核从输入的第 2 个位置开始）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_2$ (即 $i=2$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 2 \cdot 2 + j = 4 + j$。&lt;/li&gt;
&lt;li&gt;$y_2 = \sum_j v_{4+j} \cdot w_j = v_4w_0 + v_5w_1 + v_6w_2 + \dots$&lt;/li&gt;
&lt;li&gt;（核从输入的第 4 个位置开始）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结论 (Stride):&lt;/strong&gt;
请注意：从计算 $y_0$ 变到 $y_1$，你的核在输入 $v$ 上滑动（或“跳跃”）了 2 个位置（从 0 到 2）。你跳过了本应在 $s=1$ 时计算的那个输出点。
Stride 导致你计算的输出点 $y_i$ 的总数变少了。这就是缩放（下采样）效果的来源。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dilation (扩张) 的效果: $s=1, d=2$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;公式变为：&lt;/strong&gt; $l = i + 2 \cdot j$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;它在做什么：&lt;/strong&gt; 缩放&lt;strong&gt;核索引 $j$&lt;/strong&gt;。索引 $j$ 代表核 $w$ 内部的&lt;strong&gt;第几个&lt;/strong&gt;权重。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;我们来计算几个输出点：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_0$ (即 $i=0$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 0 + 2 \cdot j = 2j$。&lt;/li&gt;
&lt;li&gt;$y_0 = \sum_j v_{2j} \cdot w_j = v_0w_0 + v_2w_1 + v_4w_2 + \dots$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_1$ (即 $i=1$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 1 + 2 \cdot j = 1 + 2j$。&lt;/li&gt;
&lt;li&gt;$y_1 = \sum_j v_{1+2j} \cdot w_j = v_1w_0 + v_3w_1 + v_5w_2 + \dots$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算 $y_2$ (即 $i=2$):&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;关系是 $l = 2 + 2 \cdot j = 2 + 2j$。&lt;/li&gt;
&lt;li&gt;$y_2 = \sum_j v_{2+2j} \cdot w_j = v_2w_0 + v_4w_1 + v_6w_2 + \dots$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;结论 (Dilation):
请注意：我们没有跳过任何输出点（我们计算了 $y_0, y_1, y_2, \dots$）。
相反，为了计算单个输出点（比如 $y_0$），你的核 $w$ 的权重 ($w_0, w_1, w_2$) 被应用到了间隔更开的输入点 ($v_0, v_2, v_4$) 上。
Dilation 并没有减少输出点的数量，而是增大了单个核的感受野 (receptive field)。核被‘撑大’了，中间有了‘空洞’。这就是扩张的含义。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;二维卷积&#34;&gt;二维卷积
&lt;/h2&gt;&lt;p&gt;为简化表示，我们做如下索引替换：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输出索引为 $(a, b)$&lt;/li&gt;
&lt;li&gt;核索引为 $(c, d)$&lt;/li&gt;
&lt;li&gt;输入索引为 $(e, f)$&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;定义张量：&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;令输出张量为 $y$，其分量为 $y_{ab}$。&lt;/li&gt;
&lt;li&gt;令输入张量为 $v$，其分量为 $v_{ef}$。&lt;/li&gt;
&lt;li&gt;令核张量为 $w$，其分量为 $w_{cd}$。&lt;/li&gt;
&lt;li&gt;令 $(\star 2D)$ 卷积张量为 $C$，其分量为 $C_{abcdef}$。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;张量缩并（爱因斯坦求和形式）：&lt;/strong&gt;
完整的 2D 卷积操作（类似于 1D 情况）可以写为：
$$y_{ab} = \sum_{c,d} \sum_{e,f} C_{abcdef} \cdot v_{ef} \cdot w_{cd}$$
使用爱因斯坦求和约定（省略 $\sum$ 符号），我们得到一个非常简洁的张量形式：
$$y_{ab} = C_{abcdef} v_{ef} w_{cd}$$
&lt;ul&gt;
&lt;li&gt;$a, b$ 是&lt;strong&gt;自由索引&lt;/strong&gt;，代表输出张量的维度。&lt;/li&gt;
&lt;li&gt;$c, d, e, f$ 是&lt;strong&gt;哑索引（缩并索引）&lt;/strong&gt;，因为它们在右侧重复出现，表示需要对它们的所有可能值求和。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;六阶卷积张量 $C$ 的定义：&lt;/strong&gt;
这个六阶张量 $C_{abcdef}$ 的定义即是图像中 $(\star 2D)$ 的定义：
$$C_{abcdef} = \begin{cases} 1, &amp; \text{if } (e, f) = (a, b) + (c, d) \\ 0, &amp; \text{else} \end{cases}$$
这等价于两个独立的条件必须同时满足：
&lt;ul&gt;
&lt;li&gt;$e = a + c$&lt;/li&gt;
&lt;li&gt;$f = b + d$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;验证&lt;/strong&gt;
这种形式再次等价于标准的 2D 卷积。如果我们从 $y_{ab} = \sum_{c,d} \sum_{e,f} C_{abcdef} v_{ef} w_{cd}$ 开始：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对 $e, f$ 求和：由于 $C_{abcdef}$ 仅在 $e=a+c$ 和 $f=b+d$ 时为 1，$\sum_{e,f} C_{abcdef} v_{ef}$ 这一项塌缩为 $v_{a+c, b+d}$。&lt;/li&gt;
&lt;li&gt;代回结果：$y_{ab} = \sum_{c,d} v_{a+c, b+d} \cdot w_{cd}$。&lt;/li&gt;
&lt;li&gt;这正是 2D 卷积的标准定义（将 $(a,b)$ 视为输出坐标，$(c,d)$ 视为核坐标）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;加入步幅和膨胀&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;步幅 (Stride):&lt;/strong&gt; $s = (s_0, s_1)$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩张 (Dilation):&lt;/strong&gt; $d = (d_0, d_1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;张量缩并 (爱因斯坦求和形式):&lt;/strong&gt;
整个 2D 卷积操作（包含通道）可以写为：
$$y_{ab} = C_{abcdef} v_{ef} w_{cd}$$
&lt;ul&gt;
&lt;li&gt;$a, b$ 是&lt;strong&gt;自由索引&lt;/strong&gt;，定义了我们正在计算的输出张量的分量。&lt;/li&gt;
&lt;li&gt;$c, d, e, f$ 是&lt;strong&gt;哑索引&lt;/strong&gt;，表示我们需要对这些索引的所有可能值求和。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;六阶卷积张量 $C$ 的定义:&lt;/strong&gt;
这个六阶张量 $C$ 包含了所有关于步幅和扩张的&lt;strong&gt;结构信息&lt;/strong&gt;。其分量 $C_{abcdef}$ 定义如下：
$$C_{abcdef} = \begin{cases} 1, &amp; \text{if } (e = s_0 \cdot a + d_0 \cdot c) \quad \textbf{and} \quad (f = s_1 \cdot b + d_1 \cdot d) \\ 0, &amp; \text{else} \end{cases}$$
这个定义非常清晰地展示了 $s$ 和 $d$ 是如何分别作用于不同维度的：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;$s_0, d_0$ 掌控着第 0 维 (索引 $a, c, e$) 的映射关系。&lt;/li&gt;
&lt;li&gt;$s_1, d_1$ 掌控着第 1 维 (索引 $b, d, f$) 的映射关系。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MLP的张量表示及梯度推导</title>
        <link>http://localhost:1313/hugo_dev/p/mlp%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/</link>
        <pubDate>Mon, 17 Nov 2025 01:43:46 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/mlp%E7%9A%84%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E5%8F%8A%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC/</guid>
        <description>&lt;h2 id=&#34;代码部分&#34;&gt;代码部分
&lt;/h2&gt;&lt;p&gt;这是多层感知机（MLP）的一段示例代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;os&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatten&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_relu_stack&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReLU&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;flatten&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_relu_stack&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pred_probab&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Softmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pred_probab&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;神经网络的结构&#34;&gt;神经网络的结构
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;nn.Flatten()&lt;/code&gt;
这个函数将输入张量的各维度展平成一个向量。默认从索引1开始到索引-1结束，要注意的是索引是从0开始的，所以索引1其实是指的第2个。
这里的输入X维度为$[1,28,28]$，经过&lt;code&gt;nn.Flatten()&lt;/code&gt;后应该是$[1,28*28]$。
从张量角度看，
&lt;/p&gt;
$$
x_{b1ij}=x_{bn}, \quad n=0*28*28+i*28+j
$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;linear_relu_stack&lt;/code&gt;
这个函数将一系列的神经层排成一个列表，数据将从这些层中流出。过程中会改变维度。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Linear(28*28, 512)&lt;/code&gt;
张量表示: $y_{bm}=x_{bn}w_{nm}+\mathbf{1}_{b}b_{m}$&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReLU&lt;/code&gt;
张量表示: $y_{bm}^{r}=\text{ReLU}(y_{bm})$&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Linear(512,512)&lt;/code&gt;
张量表示: $y_{bm&#39;}&#39;=y_{bm}^{r}w_{mm&#39;}+\mathbf{1}_{b}b_{m&#39;}$&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReLU&lt;/code&gt;
张量表示: $y_{bm&#39;}^{r}=\text{ReLU}(y_{bm&#39;})$&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Linear(512,10)&lt;/code&gt;
张量表示: $y_{bo}=y_{bm&#39;}^{r}w_{m&#39;o}+\mathbf{1}_{b}b_{o}$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Softmax(dim=1)&lt;/code&gt;
张量表示：
&lt;/p&gt;
$$s_{bi}= \frac{e^{x_{bi}}}{\mathbf{1}_{kj}e^{x_{kj}}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;交叉熵损失
&lt;/p&gt;
$$
c_{b}=-\log{s_{b\text{T}}}
$$
&lt;p&gt;
交叉熵损失是单分类损失函数，这里的$\text{T}$是代表真实标签的常量索引，这里的$\text{T}$不是一种哑指标。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;推导梯度&#34;&gt;推导梯度
&lt;/h2&gt;&lt;h3 id=&#34;交叉熵部分梯度&#34;&gt;交叉熵部分梯度
&lt;/h3&gt;&lt;p&gt;重点是利用反向传播，也就是由终点向起点一层层推。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$c_{b}$
$$
\frac{\partial c_{b}}{\partial s_{ki}}=-\frac{\partial \log s_{b\text{T}}}{\partial s_{ki}}
=-\frac{1}{s_{k\text{T}}}\delta_{i\text{T}}
$$&lt;/li&gt;
&lt;li&gt;$s_{bi}$
$$
\frac{\partial s_{bi}}{\partial y_{ko}}
=\frac{\partial \mathbf{1}_{kj}e^{x_{kj}}}{\partial y_{ko}}
$$
令$\sigma=\mathbf{1}_{kj}e^{x_{kj}}$,
$$
\frac{\partial \mathbf{1}_{kj}e^{x_{kj}}}{\partial y_{ko}}
=\frac{\partial\sigma}{\partial y_{ko}}
=\frac{1}{\sigma^2}( \frac{\partial e^{y_{bi}}}{\partial y_{ko}}\sigma-e^{y_{bi}}\frac{\partial \sigma}{\partial y_{ko}})
$$
&lt;ol&gt;
&lt;li&gt;$\frac{\partial e^{y_{bi}}}{\partial y_{ko}}$
$$\frac{\partial e^{y_{bi}}}{\partial y_{ko}}
	=e^{y_{bi}}\frac{\partial y_{bi}}{\partial y_{ko}}
	=e^{y_{bi}}\delta_{bk}\delta_{io}$$&lt;/li&gt;
&lt;li&gt;$\frac{\partial \sigma}{\partial y_{ko}}$
$$\frac{\partial \sigma}{\partial y_{ko}}=\frac{\partial \mathbf{1}_{bj}e^{y_{bj}}}{\partial y_{ko}}
	=\mathbf{1}_{bj}e^{y_{bj}}\delta_{bk}\delta_{jo}=\mathbf{1}_{ko}e^{y_{ko}}
	=e^{y_{ko}} $$
代入原式：
$$
\frac{1}{\sigma^2}( \frac{\partial e^{y_{bi}}}{\partial y_{ko}}\sigma-e^{y_{bi}}\frac{\partial \sigma}{\partial y_{ko}})
=\frac{1}{\sigma^2}( e^{y_{bi}}\delta_{bk}\delta_{io}\sigma-e^{y_{bi}}e^{y_{ko}})
=s_{bi}\delta_{bk}\delta_{io}-s_{bi}s_{ko}
$$
即
$$\frac{\partial s_{bi}}{\partial y_{ko}}
=s_{bi}\delta_{bk}\delta_{io}-s_{bi}s_{ko}$$
综合一下，现在就有
$$
\frac{\partial c_{b}}{\partial y_{ko}}
=\frac{\partial c_{b}}{\partial s_{ki}}\frac{\partial s_{bi}}{\partial y_{ko}}
=-\frac{1}{s_{k\text{T}}}\delta_{i\text{T}}(s_{bi}\delta_{bk}\delta_{io}-s_{bi}s_{ko})
=s_{ko}-\delta_{bk}\delta_{To}
$$
这里可以看出，交叉熵损失在最后一层的梯度，恰好等于第$k$个样本的第$o$个logits(概率值)减去第$k$个样本的第$\text{T}$个标签(也就是1).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;单个线性层梯度&#34;&gt;单个线性层梯度
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;输入 $X$: (∗, in_features)&lt;/li&gt;
&lt;li&gt;权重 $A$ : (out_features,in_features)&lt;/li&gt;
&lt;li&gt;偏置 $b$: (out_features)&lt;/li&gt;
&lt;li&gt;输出 $Y$: (∗, out_features)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PyTorch对线性层的定义：
&lt;/p&gt;
$$
Y=XA^{T}+b
$$
&lt;p&gt;令 $C=A^{T}$ ，就有张量表示：
&lt;/p&gt;
$$
y_{ij}=x_{ik}c_{kj}+\mathbf{1}_{i}b_{j}
$$
&lt;p&gt;
上式中，$k$ 重复出现代表做了乘积，同时在等式左侧未出现，就还做了求和。$\mathbf{1}_{i}$ 用于将 $b_{j}$ 广播成矩阵。&lt;/p&gt;
&lt;p&gt;根据 &lt;a class=&#34;link&#34; href=&#34;https://robotchinwag.com/posts/linear-layer-deriving-the-gradient-for-the-backward-pass/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Linear Layer, Deriving the Gradient for the Backward Pass&lt;/a&gt; 的结果，我们有如下结论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对 $X$ 的梯度
$$\frac{\partial y_{ij}}{\partial x_{pq}}=\delta_{ip}c_{qj}$$&lt;/li&gt;
&lt;/ol&gt;
$$\begin{aligned}
\frac{\partial l}{\partial x_{pq}} &amp; =\frac{\partial l}{\partial y_{ij}}\frac{\partial y_{ij}}{\partial x_{pq}} \\
 &amp; =\frac{\partial l}{\partial y_{ij}}\delta_{ip}c_{qj} \\
 &amp; =\frac{\partial l}{\partial y_{pj}}c_{qj}
\end{aligned}$$
&lt;p&gt;
2. 对 $A$ 的梯度
&lt;/p&gt;
$$\begin{aligned}
	\frac{\partial y_{ij}}{\partial a_{pq}} &amp; =\frac{\partial}{\partial a_{pq}}[x_{ik}c_{kj}+\mathbf{1}_ib_j] \\
	 &amp; =x_{ik}\frac{\partial c_{kj}}{\partial a_{pq}}
	\end{aligned}$$
&lt;p&gt;
由于 $C=A^{T}$， 所以有 $c_{kj}=a_{jk}$ 。继续有公式：
&lt;/p&gt;
$$\begin{aligned}
	\frac{\partial y_{ij}}{\partial a_{pq}} &amp; =x_{ik}\frac{\partial a_{jk}}{\partial a_{pq}} \\
	 &amp; =x_{ik}\delta_{jp}\delta_{kq} \\
	 &amp; =x_{iq}\delta_{jp}
	\end{aligned}$$
$$\begin{aligned}
	\frac{\partial l}{\partial a_{pq}} &amp; =\frac{\partial l}{\partial y_{ij}}\frac{\partial y_{ij}}{\partial a_{pq}} \\
	 &amp; =\frac{\partial l}{\partial y_{ij}}x_{iq}\delta_{jp} \\
	 &amp; =\frac{\partial l}{\partial y_{ip}}x_{iq}
	\end{aligned}$$
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;对 $b$ 的梯度
$$\begin{aligned}
	\frac{\partial y_{ij}}{\partial b_p} &amp; =\frac{\partial}{\partial b_p}[x_{ik}c_{kj}+\mathbf{1}_ib_j] \\
	&amp; =\frac{\partial\left(\mathbf{1}_ib_j\right)}{\partial b_p} \\
	&amp; =1_i\frac{\partial b_j}{\partial b_p}
	\end{aligned}$$
$$\frac{\partial y_{ij}}{\partial b_p}=\mathbf{1}_i\delta_{jp}$$
$$\begin{aligned}
	\frac{\partial l}{\partial b_p} &amp; =\frac{\partial l}{\partial y_{ij}}\frac{\partial y_{ij}}{\partial b_p} \\
	 &amp; =\frac{\partial l}{\partial y_{ij}}\mathbf{1}_i\delta_{jp} \\
	 &amp; =\frac{\partial l}{\partial y_{ip}}\mathbf{1}_i
	\end{aligned}$$&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Hugo博客的数学公式问题</title>
        <link>http://localhost:1313/hugo_dev/p/hugo%E5%8D%9A%E5%AE%A2%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%97%AE%E9%A2%98/</link>
        <pubDate>Mon, 17 Nov 2025 01:12:58 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/hugo%E5%8D%9A%E5%AE%A2%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%97%AE%E9%A2%98/</guid>
        <description>&lt;p&gt;在探索使用hugo建立博客的过程中，遇到了数学公式难以渲染的问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如何配置hugo的数学环境&lt;/strong&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.1zh.tech/posts/hugo-papermod-math/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;如何在 Hugo 中使用数学公式？&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;tips:&lt;/strong&gt; KaTex 中的行内公式也是支持使用&lt;code&gt;$inline_equation$&lt;/code&gt;的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Markdown下的Tex渲染失败解决&lt;/strong&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://blog2.pillar.fun/p/markdown%E4%B8%8B%E7%9A%84tex%E6%B8%B2%E6%9F%93%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Markdown下的Tex渲染失败解决&lt;/a&gt;&lt;br&gt;
hugo网页渲染是网站和公式两个渲染引擎同时作用的，所以要设置优先级，让公式优先被公式引擎渲染。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KaTex常用数学公式&lt;/strong&gt;&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://kissingfire123.github.io/2022/02/18_%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8Fkatex%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/#%E9%9B%B6-%E5%89%8D%E8%A8%80&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;常用数学公式排版KaTex语法总结&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;修改完之后需要多等待几秒，网页刷新较慢。多在本地提交修改，最终再上传至仓库。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ESL第五章基展开和正则化</title>
        <link>http://localhost:1313/hugo_dev/p/esl%E7%AC%AC%E4%BA%94%E7%AB%A0%E5%9F%BA%E5%B1%95%E5%BC%80%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/</link>
        <pubDate>Fri, 13 Jun 2025 16:56:05 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/esl%E7%AC%AC%E4%BA%94%E7%AB%A0%E5%9F%BA%E5%B1%95%E5%BC%80%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/</guid>
        <description>&lt;h1 id=&#34;引言&#34;&gt;引言
&lt;/h1&gt;&lt;p&gt;超越线性模型的一种方式，就是通过增强输入 $X$ 。为 $X$ 赋予非线性，利用 $h_{m}(X)$ 张成的线性空间来讨论非线性问题，我的评价是：用非线性的砖垒一个线性的房子，来模仿非线性。（以曲代直）&lt;br&gt;
“分段多项式”和“样条”用于局部多项式表示；“小波”基，用于建模信号和图像。
各式各样的基滥用会过拟合，控制复杂度的方式有三种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;约束方法：可加性模型通过拟合各个部分函数 $f_j$ 的基函数数量$M_j$来控制复杂度（p个函数 $f_j$ ，每个函数对应 $M_j$ 个函数）&lt;/li&gt;
&lt;li&gt;选择方法：选择对拟合最有效的基函数来建模（可使用那些变量选择方案）&lt;/li&gt;
&lt;li&gt;正则化方法：岭回归、Lasso（既是正则，又是选择）&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;分段多项式与样条&#34;&gt;分段多项式与样条
&lt;/h1&gt;&lt;p&gt;分段常数是1阶样条，连续分段线性函数是2阶样条。以下是阶段幂基函数的广义形式：
&lt;/p&gt;
$$
h_{j}^{}\left( X \right) =X_{}^{j-1},\ j=1,...,M, \\
h_{M+l}\left( X \right) =\left( X-\xi _l \right) _{+}^{M-1},\ l=1,...,K.
$$
&lt;p&gt;上式中的 $h_j(X)$ 是起始点的各阶基函数， $h_{M+l}(X)$ 是分段后的基函数。&lt;br&gt;
于是原函数可以被这些基函数线性表示，基的数量计算：&lt;br&gt;
基函数个数 = (区域数) * (每区域参数个数) - (分段点个数) * (每个分段点的约束数量)，即：&lt;/p&gt;
$$
\left( K+1 \right) \times \left( M \right) -\left( K \right) \times \left( M-1 \right) 
$$
&lt;p&gt;这些固定节点的样条都称为&lt;strong&gt;回归样条&lt;/strong&gt;，这些方法需要选择样条的阶数、节点的个数和位置。&lt;/p&gt;
&lt;h1 id=&#34;正则化和再生核希尔伯特空间rkhs&#34;&gt;正则化和再生核希尔伯特空间（RKHS）
&lt;/h1&gt;&lt;p&gt;广义的正则化问题，即使是在无穷维函数空间上，它的解依然是有限维的。
基于正定核的问题，相关的函数空间就是RKHS&lt;/p&gt;
&lt;h1 id=&#34;方法关系&#34;&gt;方法关系
&lt;/h1&gt;&lt;p&gt;多项式样条在结点变大时导致严重的舍入问题，此时可以用B-样条（B-Spline），它在结点K变大的同时保持了高效计算效率。
多项式样条在边界上不稳定导致了外推功能较差，此时可以使用自然立方样条（Natural Cubic Spline）&lt;br&gt;
多维样条分为&lt;strong&gt;张量积样条&lt;/strong&gt;和&lt;strong&gt;方差分析样条分解&lt;/strong&gt;。前者在特征维度较大时，计算量指数上升；后者通过指定交互阶数，将 $h_m(x)h_n(y)$ 变为 $h(x,y)$ ，减少了计算量。
多维样条是平滑样条的多维扩展&lt;br&gt;
方差样条分解是多维样条的扩展&lt;br&gt;
当潜在特征数量较大时，自动方法更可取，MARS（多元自适应回归样条）和MART（多重加法回归树）方法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;树方法也是样条方法的一种，这值得思考，我认为树方法主要是在基函数上有不同&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基函数：&lt;strong&gt;截断幂基&lt;/strong&gt;、&lt;strong&gt;自然立方样条&lt;/strong&gt;、&lt;strong&gt;B-样条&lt;/strong&gt;、&lt;strong&gt;光滑样条&lt;/strong&gt;（局部多项式表示，便于无穷维空间内积），&lt;strong&gt;高斯径向基&lt;/strong&gt;（全局表示，但随距离衰减），&lt;strong&gt;小波基&lt;/strong&gt;（严格局部且多分辨率）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;选择多项式样条，当你认为数据的底层行为是分段变化的，并且你想在不同区域使用不同的简单模型时。
选择高斯RBF，当你需要拟合一个整体上非常平滑但高度非线性的函数，并且数据点之间的距离是关键信息时。
选择小波基，当你的数据（或函数）在不同位置表现出不同尺度的特征时，尤其是包含大量平滑区域和少数尖锐变化（如信号处理、图像压缩和金融时间序列分析）的场景。小波能够自适应地在需要的地方提供更高的分辨率，这是其无与伦比的优势。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;!!! tips 小波对图像的分解，是否能用于多分辨率扩散去噪模型？
有待探索&lt;/p&gt;
</description>
        </item>
        <item>
        <title>深度学习理论笔记</title>
        <link>http://localhost:1313/hugo_dev/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E7%AC%94%E8%AE%B0/</link>
        <pubDate>Thu, 12 Jun 2025 12:03:02 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E7%AC%94%E8%AE%B0/</guid>
        <description>&lt;p&gt;梯度下降对于线性可分数据和线性不可分数据的隐性偏置描述是不同的&lt;/p&gt;
&lt;h3 id=&#34;定理-931&#34;&gt;定理 9.3.1
&lt;/h3&gt;&lt;p&gt;对于几乎所有的线性可分数据集，采用梯度下降法进行更新，其中初始化权重 $w_0$ 和步长的选择都旨在最小化指数损失：
&lt;/p&gt;
$$
L(w) = \sum_{i=1}^{n} \exp\left(-y^{(i)} w^T x^{(i)}\right)
$$
&lt;p&gt;
即，$L(w_t) \to 0$。梯度下降法的迭代过程最终会收敛至 $l_2$ 最大间隔向量的方向，即 $\lim_{t \to \infty} \frac{w_t}{||w_t||_2} = \frac{\hat{w}}{||\hat{w}||_2}$，此处的 $\hat{w}$ 为：
&lt;/p&gt;
$$
\hat{w} = \underset{w}{\arg\min} \, ||w||_2^2 \quad \text{s.t.} \quad \forall i, \, y^{(i)} w^T x^{(i)} \ge 1
$$
&lt;p&gt;
不失一般性，假设 $\forall i, y^{(i)} = 1$ 作为线性模型的符号，因为该符号可以被合并到 $x^{(i)}$ 中。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hugo个人博客搭建</title>
        <link>http://localhost:1313/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
        <pubDate>Sat, 07 Jun 2025 15:32:24 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
        <description>&lt;h1 id=&#34;hugo的下载与安装&#34;&gt;Hugo的下载与安装
&lt;/h1&gt;&lt;p&gt;下载Hugo网址：gohugo.io&lt;br&gt;
进入下载页面后，点击Github页面的tag，选择v0.131.0版本
创建新的站点：&lt;code&gt;hugo new site [site-name]&lt;/code&gt;
创建新的博客文章：&lt;code&gt;hugo new content post/&amp;lt;FOLDERNAME&amp;gt;/&amp;lt;FILENAME&amp;gt;.&amp;lt;FORMAT&amp;gt;&lt;/code&gt;&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image.png&#34;
	width=&#34;737&#34;
	height=&#34;18&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image_hu9503583853400636610.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image_hu12270748714401338735.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;alt text&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;4094&#34;
		data-flex-basis=&#34;9826px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;hugo的配置&#34;&gt;Hugo的配置
&lt;/h1&gt;&lt;h2 id=&#34;stack-主题配置&#34;&gt;Stack 主题配置
&lt;/h2&gt;&lt;p&gt;hugo主题配置主要修改&lt;code&gt;hugo.yaml&lt;/code&gt;这个文件，下面介绍一下这个文件中的各个参数。&lt;/p&gt;
&lt;h3 id=&#34;文件hugoyaml参数说明&#34;&gt;文件&lt;code&gt;hugo.yaml&lt;/code&gt;参数说明
&lt;/h3&gt;&lt;p&gt;baseurl 指站点网址，配置完Github仓库后可以修改&lt;br&gt;
paginate 指一页几篇文章&lt;br&gt;
copyright 版权所有，改成自己即可&lt;br&gt;
DefaultContentLanguage 站点默认语言，支持很多种选择zh-cn即可&lt;br&gt;
hasCJKLanguage 如果默认语言是中文zh-cn，那要改成True&lt;br&gt;
favicon 用于修改标签页的小图标&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-15-50-09.png&#34;
	width=&#34;300&#34;
	height=&#34;43&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-15-50-09_hu17482938559111274613.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-15-50-09_hu11539225289073693534.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;c&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;697&#34;
		data-flex-basis=&#34;1674px&#34;
	
&gt;&lt;br&gt;
emoji 网上找一个emoji复制粘贴即可&lt;br&gt;
avatar 是个人头像，网上搜一个放在对应文件夹下：
&lt;code&gt;..\assets\img\avatar.png&lt;/code&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-17-45.png&#34;
	width=&#34;739&#34;
	height=&#34;152&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-17-45_hu17797907504984970113.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-17-45_hu3133452838774941380.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;486&#34;
		data-flex-basis=&#34;1166px&#34;
	
&gt;&lt;br&gt;
subtitle 是个头像下面的文字&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-19-46.png&#34;
	width=&#34;207&#34;
	height=&#34;251&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-19-46_hu1809174856519036080.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-19-46_hu6394028429084804009.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;82&#34;
		data-flex-basis=&#34;197px&#34;
	
&gt;&lt;br&gt;
comments 是评论系统，官方文档提供了很多评论系统的支持&lt;br&gt;
修改下面图片中的英文：&lt;br&gt;
&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-47-06.png&#34;
	width=&#34;170&#34;
	height=&#34;416&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-47-06_hu12613844106178746379.png 480w, http://localhost:1313/hugo_dev/hugo_dev/p/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/2025-06-07-16-47-06_hu11275444441373999250.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;40&#34;
		data-flex-basis=&#34;98px&#34;
	
&gt;&lt;br&gt;
&lt;code&gt;..\content\page&lt;/code&gt; 中的文件夹内index.md中的title和图片中英文一一对应，修改即可&lt;/p&gt;
&lt;h3 id=&#34;utterances搭建评论系统&#34;&gt;Utterances搭建评论系统
&lt;/h3&gt;&lt;h1 id=&#34;文章发布&#34;&gt;文章发布
&lt;/h1&gt;&lt;p&gt;每次新的文章发布后都要用这个代码刷新一下服务器：&lt;code&gt;hugo server -D&lt;/code&gt;&lt;/p&gt;
&lt;h1 id=&#34;github部署&#34;&gt;Github部署
&lt;/h1&gt;</description>
        </item>
        <item>
        <title>DataManagement</title>
        <link>http://localhost:1313/hugo_dev/p/datamanagement/</link>
        <pubDate>Wed, 30 Apr 2025 10:40:07 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/datamanagement/</guid>
        <description>&lt;h1 id=&#34;亚马逊电商运营工作期间的一些总结&#34;&gt;亚马逊电商运营工作期间的一些总结
&lt;/h1&gt;&lt;p&gt;本人有幸参与过亚马逊电商运营的相关工作，其中主要涉及广告运营等内容。这部分与数据运营、计算广告、推荐系统有一定关系。希望从商家运营的角度出发做一些回顾与思考，希望对于推广搜有一定启发。先开个坑，日后慢慢填。
在运营方面的知识主要来源于上班期间上司的指导交流以及“知无不言”电商论坛。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;暂定内容计划：1. 亚马逊广告类型 2. 广告投放心得 3. 亚马逊平台的局限——独立站的重要性 4. 亚马逊平台的更新&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>MyFirstBlog</title>
        <link>http://localhost:1313/hugo_dev/p/myfirstblog/</link>
        <pubDate>Wed, 30 Apr 2025 00:17:45 +0800</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/myfirstblog/</guid>
        <description>&lt;h3 id=&#34;hello-world&#34;&gt;Hello, WOrld!
&lt;/h3&gt;</description>
        </item>
        <item>
        <title>Chinese Test</title>
        <link>http://localhost:1313/hugo_dev/p/test-chinese/</link>
        <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/test-chinese/</guid>
        <description>&lt;img src="http://localhost:1313/hugo_dev/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash.jpg" alt="Featured image of post Chinese Test" /&gt;&lt;h2 id=&#34;正文测试&#34;&gt;正文测试
&lt;/h2&gt;&lt;p&gt;而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。&lt;/p&gt;
&lt;p&gt;奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。&lt;/p&gt;
&lt;h2 id=&#34;引用&#34;&gt;引用
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;思念是最暖的忧伤像一双翅膀&lt;br&gt;
让我停不了飞不远在过往游荡&lt;br&gt;
不告而别的你 就算为了我着想&lt;br&gt;
这么沉痛的呵护 我怎么能翱翔&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=3aypp_YlBzI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;最暖的憂傷 - 田馥甄&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;图片&#34;&gt;图片
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/florian-klauer-nptLmg6jqDo-unsplash.jpg&#34;
	width=&#34;667&#34;
	height=&#34;1000&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/florian-klauer-nptLmg6jqDo-unsplash_hu13768363498926278726.jpg 480w, http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/florian-klauer-nptLmg6jqDo-unsplash_hu13380208884366868750.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Florian Klauer on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;66&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;  &lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/luca-bravo-alS7ewQ41M8-unsplash.jpg&#34;
	width=&#34;1000&#34;
	height=&#34;667&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/luca-bravo-alS7ewQ41M8-unsplash_hu1712544344331247820.jpg 480w, http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/luca-bravo-alS7ewQ41M8-unsplash_hu12475395149584884402.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Luca Bravo on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash.jpg&#34;
	width=&#34;1000&#34;
	height=&#34;750&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu8363585391189779282.jpg 480w, http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu15102473124145023839.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Helena Hertz on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;  &lt;img src=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/hudai-gayiran-3Od_VKcDEAA-unsplash.jpg&#34;
	width=&#34;667&#34;
	height=&#34;1000&#34;
	srcset=&#34;http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/hudai-gayiran-3Od_VKcDEAA-unsplash_hu15886963791847885497.jpg 480w, http://localhost:1313/hugo_dev/hugo_dev/p/test-chinese/hudai-gayiran-3Od_VKcDEAA-unsplash_hu11726476772237334826.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Hudai Gayiran on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;66&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Florian Klauer on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;florian-klauer-nptLmg6jqDo-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Luca Bravo on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;luca-bravo-alS7ewQ41M8-unsplash.jpg&lt;/span&gt;) 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Helena Hertz on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;helena-hertz-wWZzXlDpMog-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Hudai Gayiran on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;hudai-gayiran-3Od_VKcDEAA-unsplash.jpg&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;相册语法来自 &lt;a class=&#34;link&#34; href=&#34;https://typlog.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Typlog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>http://localhost:1313/hugo_dev/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>Markdown Syntax Guide</title>
        <link>http://localhost:1313/hugo_dev/p/markdown-syntax-guide/</link>
        <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/markdown-syntax-guide/</guid>
        <description>&lt;img src="http://localhost:1313/hugo_dev/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash.jpg" alt="Featured image of post Markdown Syntax Guide" /&gt;&lt;p&gt;This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.&lt;/p&gt;
&lt;h2 id=&#34;headings&#34;&gt;Headings
&lt;/h2&gt;&lt;p&gt;The following HTML &lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt;—&lt;code&gt;&amp;lt;h6&amp;gt;&lt;/code&gt; elements represent six levels of section headings. &lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; is the highest section level while &lt;code&gt;&amp;lt;h6&amp;gt;&lt;/code&gt; is the lowest.&lt;/p&gt;
&lt;h1 id=&#34;h1&#34;&gt;H1
&lt;/h1&gt;&lt;h2 id=&#34;h2&#34;&gt;H2
&lt;/h2&gt;&lt;h3 id=&#34;h3&#34;&gt;H3
&lt;/h3&gt;&lt;h4 id=&#34;h4&#34;&gt;H4
&lt;/h4&gt;&lt;h5 id=&#34;h5&#34;&gt;H5
&lt;/h5&gt;&lt;h6 id=&#34;h6&#34;&gt;H6
&lt;/h6&gt;&lt;h2 id=&#34;paragraph&#34;&gt;Paragraph
&lt;/h2&gt;&lt;p&gt;Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.&lt;/p&gt;
&lt;p&gt;Itatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.&lt;/p&gt;
&lt;h2 id=&#34;blockquotes&#34;&gt;Blockquotes
&lt;/h2&gt;&lt;p&gt;The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a &lt;code&gt;footer&lt;/code&gt; or &lt;code&gt;cite&lt;/code&gt; element, and optionally with in-line changes such as annotations and abbreviations.&lt;/p&gt;
&lt;h4 id=&#34;blockquote-without-attribution&#34;&gt;Blockquote without attribution
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Tiam, ad mint andaepu dandae nostion secatur sequo quae.
&lt;strong&gt;Note&lt;/strong&gt; that you can use &lt;em&gt;Markdown syntax&lt;/em&gt; within a blockquote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;blockquote-with-attribution&#34;&gt;Blockquote with attribution
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t communicate by sharing memory, share memory by communicating.&lt;br&gt;
— &lt;cite&gt;Rob Pike&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;tables&#34;&gt;Tables
&lt;/h2&gt;&lt;p&gt;Tables aren&amp;rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Age&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Bob&lt;/td&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alice&lt;/td&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;inline-markdown-within-tables&#34;&gt;Inline Markdown within tables
&lt;/h4&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Italics&lt;/th&gt;
&lt;th&gt;Bold&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;italics&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;bold&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;code&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;A&lt;/th&gt;
&lt;th&gt;B&lt;/th&gt;
&lt;th&gt;C&lt;/th&gt;
&lt;th&gt;D&lt;/th&gt;
&lt;th&gt;E&lt;/th&gt;
&lt;th&gt;F&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/td&gt;
&lt;td&gt;Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex.&lt;/td&gt;
&lt;td&gt;Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus&lt;/td&gt;
&lt;td&gt;Proin sit amet velit nec enim imperdiet vehicula.&lt;/td&gt;
&lt;td&gt;Ut bibendum vestibulum quam, eu egestas turpis gravida nec&lt;/td&gt;
&lt;td&gt;Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;code-blocks&#34;&gt;Code Blocks
&lt;/h2&gt;&lt;h4 id=&#34;code-block-with-backticks&#34;&gt;Code block with backticks
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;html&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;en&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meta&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;charset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Example HTML5 Document&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Test&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;html&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h4 id=&#34;code-block-indented-with-four-spaces&#34;&gt;Code block indented with four spaces
&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt;
&amp;lt;head&amp;gt;
  &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
  &amp;lt;title&amp;gt;Example HTML5 Document&amp;lt;/title&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;p&amp;gt;Test&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;code-block-with-hugos-internal-highlight-shortcode&#34;&gt;Code block with Hugo&amp;rsquo;s internal highlight shortcode
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;html&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;lang&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;en&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;meta&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;charset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Example HTML5 Document&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;Test&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;html&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;diff-code-block&#34;&gt;Diff code block
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-diff&#34; data-lang=&#34;diff&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[dependencies.bevy]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git = &amp;#34;https://github.com/bevyengine/bevy&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;rev = &amp;#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gd&#34;&gt;- features = [&amp;#34;dynamic&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;gd&#34;&gt;&lt;/span&gt;&lt;span class=&#34;gi&#34;&gt;+ features = [&amp;#34;jpeg&amp;#34;, &amp;#34;dynamic&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;list-types&#34;&gt;List Types
&lt;/h2&gt;&lt;h4 id=&#34;ordered-list&#34;&gt;Ordered List
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;First item&lt;/li&gt;
&lt;li&gt;Second item&lt;/li&gt;
&lt;li&gt;Third item&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;unordered-list&#34;&gt;Unordered List
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;List item&lt;/li&gt;
&lt;li&gt;Another item&lt;/li&gt;
&lt;li&gt;And another item&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;nested-list&#34;&gt;Nested list
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Fruit
&lt;ul&gt;
&lt;li&gt;Apple&lt;/li&gt;
&lt;li&gt;Orange&lt;/li&gt;
&lt;li&gt;Banana&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dairy
&lt;ul&gt;
&lt;li&gt;Milk&lt;/li&gt;
&lt;li&gt;Cheese&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-elements--abbr-sub-sup-kbd-mark&#34;&gt;Other Elements — abbr, sub, sup, kbd, mark
&lt;/h2&gt;&lt;p&gt;&lt;abbr title=&#34;Graphics Interchange Format&#34;&gt;GIF&lt;/abbr&gt; is a bitmap image format.&lt;/p&gt;
&lt;p&gt;H&lt;sub&gt;2&lt;/sub&gt;O&lt;/p&gt;
&lt;p&gt;X&lt;sup&gt;n&lt;/sup&gt; + Y&lt;sup&gt;n&lt;/sup&gt; = Z&lt;sup&gt;n&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Press &lt;kbd&gt;CTRL&lt;/kbd&gt; + &lt;kbd&gt;ALT&lt;/kbd&gt; + &lt;kbd&gt;Delete&lt;/kbd&gt; to end the session.&lt;/p&gt;
&lt;p&gt;Most &lt;mark&gt;salamanders&lt;/mark&gt; are nocturnal, and hunt for insects, worms, and other small creatures.&lt;/p&gt;
&lt;h2 id=&#34;hyperlinked-image&#34;&gt;Hyperlinked image
&lt;/h2&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://google.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://www.google.com/images/branding/googlelogo/1x/googlelogo_light_color_272x92dp.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Google&#34;
	
	
&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;The above quote is excerpted from Rob Pike&amp;rsquo;s &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=PAAkCSZUG1c&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;talk&lt;/a&gt; during Gopherfest, November 18, 2015.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Placeholder Text</title>
        <link>http://localhost:1313/hugo_dev/p/placeholder-text/</link>
        <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/placeholder-text/</guid>
        <description>&lt;img src="http://localhost:1313/hugo_dev/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash.jpg" alt="Featured image of post Placeholder Text" /&gt;&lt;p&gt;Lorem est tota propiore conpellat pectoribus de pectora summo.&lt;/p&gt;
&lt;p&gt;Redit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Exierant elisi ambit vivere dedere&lt;/li&gt;
&lt;li&gt;Duce pollice&lt;/li&gt;
&lt;li&gt;Eris modo&lt;/li&gt;
&lt;li&gt;Spargitque ferrea quos palude&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Comas hunc haec pietate fetum procerum dixit&lt;/li&gt;
&lt;li&gt;Post torum vates letum Tiresia&lt;/li&gt;
&lt;li&gt;Flumen querellas&lt;/li&gt;
&lt;li&gt;Arcanaque montibus omnes&lt;/li&gt;
&lt;li&gt;Quidem et&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;vagus-elidunt&#34;&gt;Vagus elidunt
&lt;/h1&gt;&lt;p&gt;&lt;svg class=&#34;canon&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; overflow=&#34;visible&#34; viewBox=&#34;0 0 496 373&#34; height=&#34;373&#34; width=&#34;496&#34;&gt;&lt;g fill=&#34;none&#34;&gt;&lt;path stroke=&#34;#000&#34; stroke-width=&#34;.75&#34; d=&#34;M.599 372.348L495.263 1.206M.312.633l494.95 370.853M.312 372.633L247.643.92M248.502.92l246.76 370.566M330.828 123.869V1.134M330.396 1.134L165.104 124.515&#34;&gt;&lt;/path&gt;&lt;path stroke=&#34;#ED1C24&#34; stroke-width=&#34;.75&#34; d=&#34;M275.73 41.616h166.224v249.05H275.73zM54.478 41.616h166.225v249.052H54.478z&#34;&gt;&lt;/path&gt;&lt;path stroke=&#34;#000&#34; stroke-width=&#34;.75&#34; d=&#34;M.479.375h495v372h-495zM247.979.875v372&#34;&gt;&lt;/path&gt;&lt;ellipse cx=&#34;498.729&#34; cy=&#34;177.625&#34; rx=&#34;.75&#34; ry=&#34;1.25&#34;&gt;&lt;/ellipse&gt;&lt;ellipse cx=&#34;247.229&#34; cy=&#34;377.375&#34; rx=&#34;.75&#34; ry=&#34;1.25&#34;&gt;&lt;/ellipse&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://en.wikipedia.org/wiki/Canons_of_page_construction#Van_de_Graaf_canon&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;The Van de Graaf Canon&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;mane-refeci-capiebant-unda-mulcebat&#34;&gt;Mane refeci capiebant unda mulcebat
&lt;/h2&gt;&lt;p&gt;Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. &lt;strong&gt;Faces illo pepulere&lt;/strong&gt; tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.&lt;/p&gt;
&lt;p&gt;Iubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.&lt;/p&gt;
&lt;p&gt;Eurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel &lt;strong&gt;mitis temploque&lt;/strong&gt; vocatus, inque alis, &lt;em&gt;oculos nomen&lt;/em&gt; non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides &lt;strong&gt;parte&lt;/strong&gt;.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Math Typesetting</title>
        <link>http://localhost:1313/hugo_dev/p/math-typesetting/</link>
        <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/math-typesetting/</guid>
        <description>&lt;p&gt;Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.&lt;/p&gt;
&lt;p&gt;In this example we will be using &lt;a class=&#34;link&#34; href=&#34;https://katex.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;KaTeX&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a partial under &lt;code&gt;/layouts/partials/math.html&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Within this partial reference the &lt;a class=&#34;link&#34; href=&#34;https://katex.org/docs/autorender.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Auto-render Extension&lt;/a&gt; or host these scripts locally.&lt;/li&gt;
&lt;li&gt;Include the partial in your templates like so:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; or .Params.math .Site.Params.math &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; partial &lt;span class=&#34;s2&#34;&gt;&amp;#34;math.html&amp;#34;&lt;/span&gt; . &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;{{&lt;/span&gt; end &lt;span class=&#34;o&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;To enable KaTeX globally set the parameter &lt;code&gt;math&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in a project&amp;rsquo;s configuration&lt;/li&gt;
&lt;li&gt;To enable KaTeX on a per page basis include the parameter &lt;code&gt;math: true&lt;/code&gt; in content files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Use the online reference of &lt;a class=&#34;link&#34; href=&#34;https://katex.org/docs/supported.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Supported TeX Functions&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples
&lt;/h3&gt;&lt;p&gt;Inline math: $\varphi = \dfrac{1+\sqrt5}{2}= 1.6180339887…$&lt;/p&gt;
&lt;p&gt;Block math:
&lt;/p&gt;
$$
 \varphi = 1+\frac{1} {1+\frac{1} {1+\frac{1} {1+\cdots} } } 
$$</description>
        </item>
        <item>
        <title>Emoji Support</title>
        <link>http://localhost:1313/hugo_dev/p/emoji-support/</link>
        <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/emoji-support/</guid>
        <description>&lt;img src="http://localhost:1313/hugo_dev/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash.jpg" alt="Featured image of post Emoji Support" /&gt;&lt;p&gt;Emoji can be enabled in a Hugo project in a number of ways.&lt;/p&gt;
&lt;p&gt;The &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/functions/emojify/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;code&gt;emojify&lt;/code&gt;&lt;/a&gt; function can be called directly in templates or &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/templates/shortcode-templates/#inline-shortcodes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Inline Shortcodes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To enable emoji globally, set &lt;code&gt;enableEmoji&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in your site&amp;rsquo;s &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/configuration/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;configuration&lt;/a&gt; and then you can type emoji shorthand codes directly in content files; e.g.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;nowrap&#34;&gt;&lt;span class=&#34;emojify&#34;&gt;🙈&lt;/span&gt; &lt;code&gt;:see_no_evil:&lt;/code&gt;&lt;/span&gt;  &lt;span class=&#34;nowrap&#34;&gt;&lt;span class=&#34;emojify&#34;&gt;🙉&lt;/span&gt; &lt;code&gt;:hear_no_evil:&lt;/code&gt;&lt;/span&gt;  &lt;span class=&#34;nowrap&#34;&gt;&lt;span class=&#34;emojify&#34;&gt;🙊&lt;/span&gt; &lt;code&gt;:speak_no_evil:&lt;/code&gt;&lt;/span&gt;&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;The &lt;a class=&#34;link&#34; href=&#34;http://www.emoji-cheat-sheet.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Emoji cheat sheet&lt;/a&gt; is a useful reference for emoji shorthand codes.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;N.B.&lt;/strong&gt; The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.emoji {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title></title>
        <link>http://localhost:1313/hugo_dev/p/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/p/</guid>
        <description>&lt;p&gt;#代码数学化&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;自注意力&#34;&gt;自注意力
&lt;/h2&gt;&lt;h3 id=&#34;代码部分&#34;&gt;代码部分
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SelfAttention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;attn_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;context_vecs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;context_vecs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;前向过程&#34;&gt;前向过程
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;索引和张量定义&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$t_1, t_2$: Token/序列 (Sequence) 索引。$t_1$ 代表查询 (Query)，$t_2$ 代表键/值 (Key/Value)。&lt;/li&gt;
&lt;li&gt;$i, k$: 输入特征维度 ($d\_in$) 的索引。&lt;/li&gt;
&lt;li&gt;$j$: 输出/内部特征维度 ($d\_out$) 的索引。
&lt;strong&gt;输入张量：&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Input $X$:&lt;/strong&gt; $X_{ti}$ (对应代码中的 &lt;code&gt;x&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Query Weights $W_Q$:&lt;/strong&gt; $W^Q_{ji}$ (对应 &lt;code&gt;self.W_q.weight&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key Weights $W_K$:&lt;/strong&gt; $W^K_{jk}$ (对应 &lt;code&gt;self.W_k.weight&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value Weights $W_V$:&lt;/strong&gt; $W^V_{jk}$ (对应 &lt;code&gt;self.W_v.weight&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output $Y$:&lt;/strong&gt; $Y_{t_1 j}$ (对应 &lt;code&gt;context_vecs&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;q, k, v&lt;/code&gt; 的计算 (线性)&lt;/strong&gt;
这是输入 $X$ 和权重矩阵之间的张量缩并（矩阵乘法）。
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Query:&lt;/strong&gt; $Q_{t_1 j} = X_{t_1 i} W^Q_{ji}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key:&lt;/strong&gt; $K_{t_2 j} = X_{t_2 k} W^K_{jk}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value:&lt;/strong&gt; $V_{t_2 j} = X_{t_2 k} W^V_{jk}$
（在爱因斯坦约定中，重复的索引 $i$ 和 $k$ 表示在 $d\_in$ 维度上求和。）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;attn_scores&lt;/code&gt; 的计算 (线性)&lt;/strong&gt;
&lt;code&gt;attn_scores = torch.matmul(q, k.T)&lt;/code&gt;。这是一个矩阵乘法，它在 $j$ (即 $d\_out$) 维度上进行缩并。
&lt;ul&gt;
&lt;li&gt;$S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;attn_weights&lt;/code&gt; 的计算 (非线性)&lt;/strong&gt;
&lt;code&gt;attn_weights = torch.softmax(...)&lt;/code&gt;。这一步是&lt;strong&gt;非线性的&lt;/strong&gt;，不能用简单的张量缩并表示。我们将其定义为函数 $A = \text{softmax}(S&#39;)$：
&lt;ul&gt;
&lt;li&gt;$S&#39;_{t_1 t_2} = S_{t_1 t_2} / \sqrt{d_{out}}$&lt;/li&gt;
&lt;li&gt;$A_{t_1 t_2} = \frac{\exp(S&#39;_{t_1 t_2})}{\mathbf{1}_{t_2&#39;} \exp(S&#39;_{t_1 t_2&#39;})}$
$A_{t_1 t_2}$ 是最终的注意力权重矩阵。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;context_vecs&lt;/code&gt; 的计算 (线性)&lt;/strong&gt;
&lt;code&gt;context_vecs = torch.matmul(attn_weights, v)&lt;/code&gt;。这是注意力权重 $A$ 和值 $V$ 之间的矩阵乘法。它在 $t_2$ 维度（序列）上进行缩并：
$$Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$$&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;总结：组合的张量形式&lt;/strong&gt;
我们可以把这些步骤代入，得到一个更完整的（但分步的）张量表示：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算分数 (Scores):
$$S_{t_1 t_2} = (X_{t_1 i} W^Q_{ji}) (X_{t_2 k} W^K_{jk})$$&lt;/li&gt;
&lt;li&gt;应用非线性 (Softmax):
$$A_{t_1 t_2} = \text{softmax}\left( \frac{S_{t_1 t_2}}{\sqrt{d_{out}}} \right)$$&lt;/li&gt;
&lt;li&gt;计算上下文 (Context):
$$Y_{t_1 j} = A_{t_1 t_2} (X_{t_2 k} W^V_{jk})$$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终的输出 $Y_{t_1 j}$ 是&lt;strong&gt;所有 $t_2$ 位置的值&lt;/strong&gt;（经过 $W^V$ 变换后）的&lt;strong&gt;动态加权和&lt;/strong&gt;，权重 $A_{t_1 t_2}$ 是根据查询和键（$X$ 和 $W^Q, W^K$）动态计算出来的。&lt;/p&gt;
&lt;h3 id=&#34;反向传播梯度推导&#34;&gt;反向传播（梯度推导）
&lt;/h3&gt;&lt;p&gt;这非常关键，因为 $A \rightarrow S$ 这一步是反向传播（backpropagation）通过 Softmax 函数，是整个过程中最复杂的部分。&lt;/p&gt;
&lt;p&gt;下面是完整的、包含所有步骤的推导。&lt;/p&gt;
&lt;h4 id=&#34;引言和符号定义&#34;&gt;引言和符号定义
&lt;/h4&gt;&lt;p&gt;我们将遵循您的爱因斯坦求和约定（重复的索引表示在该维度上求和）。&lt;/p&gt;
&lt;p&gt;已知（上游梯度）：&lt;/p&gt;
&lt;p&gt;我们假设我们已经拥有了损失 $L$ 相对于注意力层最终输出 $Y$ 的梯度。我们将其定义为 $G^Y$：&lt;/p&gt;
$$G^Y_{t_1 j} = \frac{\partial L}{\partial Y_{t_1 j}}$$
&lt;p&gt;目标：&lt;/p&gt;
&lt;p&gt;我们希望求解以下三个梯度：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$\frac{\partial L}{\partial W^V_{jk}}$ (Value 权重)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\frac{\partial L}{\partial W^Q_{ji}}$ (Query 权重)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\frac{\partial L}{\partial W^K_{jk}}$ (Key 权重)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;中间梯度符号：&lt;/p&gt;
&lt;p&gt;为了使推导更清晰，我们定义 $G^Z = \frac{\partial L}{\partial Z}$，表示 $L$ 对任意中间张量 $Z$ 的梯度。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;第-1-部分wv-value-的梯度推导&#34;&gt;第 1 部分：$W^V$ (Value) 的梯度推导
&lt;/h4&gt;&lt;p&gt;此路径不经过 Softmax，最为直接。&lt;/p&gt;
&lt;p&gt;反向传播路径是：$L \rightarrow Y \rightarrow V \rightarrow W^V$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤 1.1：计算 $\frac{\partial L}{\partial V}$ (即 $G^V$)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则： 我们对一个特定的 $V_{t_2 j}$ 求导：&lt;/p&gt;
$$G^V_{t_2 j} = \frac{\partial L}{\partial V_{t_2 j}} = \frac{\partial L}{\partial Y_{t_1&#39; j&#39;}} \frac{\partial Y_{t_1&#39; j&#39;}}{\partial V_{t_2 j}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial Y_{t_1&#39; j&#39;}}{\partial V_{t_2 j}} = \frac{\partial (A_{t_1&#39; t_2&#39;} V_{t_2&#39; j&#39;})}{\partial V_{t_2 j}} = A_{t_1&#39; t_2} \delta_{j&#39; j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$G^V_{t_2 j} = G^Y_{t_1 j} A_{t_1 t_2}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 1.2：计算 $\frac{\partial L}{\partial W^V}$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $V_{t_2 j} = X_{t_2 k} W^V_{jk}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
$$\frac{\partial L}{\partial W^V_{jk}} = \frac{\partial L}{\partial V_{t_2&#39; j&#39;}} \frac{\partial V_{t_2&#39; j&#39;}}{\partial W^V_{jk}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial V_{t_2&#39; j&#39;}}{\partial W^V_{jk}} = \frac{\partial (X_{t_2&#39; k&#39;} W^V_{j&#39; k&#39;})}{\partial W^V_{jk}} = X_{t_2&#39; k} \delta_{j&#39; j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$\frac{\partial L}{\partial W^V_{jk}} = G^V_{t_2 j} X_{t_2 k}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;$W^V$ 梯度总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将步骤 1.1 代入 1.2，得到 $W^V$ 的最终梯度：&lt;/p&gt;
$$\frac{\partial L}{\partial W^V_{jk}} = (G^Y_{t_1 j} A_{t_1 t_2}) X_{t_2 k}$$
&lt;hr&gt;
&lt;h4 id=&#34;第-2-部分wq-query-和-wk-key-的梯度推导&#34;&gt;第 2 部分：$W^Q$ (Query) 和 $W^K$ (Key) 的梯度推导
&lt;/h4&gt;&lt;p&gt;此路径是 $L \rightarrow Y \rightarrow A \rightarrow S&#39; \rightarrow S \rightarrow \{Q, K\} \rightarrow \{W^Q, W^K\}$。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.1：计算 $\frac{\partial L}{\partial A}$ (即 $G^A$)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
$$G^A_{t_1 t_2} = \frac{\partial L}{\partial A_{t_1 t_2}} =\frac{\partial L}{\partial Y_{t_1&#39; j&#39;}} \frac{\partial Y_{t_1&#39; j&#39;}}{\partial A_{t_1 t_2}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial Y_{t_1&#39; j&#39;}}{\partial A_{t_1 t_2}} = \frac{\partial (A_{t_1&#39; t_2&#39;} V_{t_2&#39; j&#39;})}{\partial A_{t_1 t_2}} = \delta_{t_1&#39; t_1} V_{t_2 j&#39;}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$G^A_{t_1 t_2} = G^Y_{t_1 j} V_{t_2 j}$$
&lt;p&gt;（这是我们上一个回答的结论，现在它将作为 $G^S$ 推导的起点。）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.2：计算 $\frac{\partial L}{\partial S}$ (即 $G^S$)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是最关键的步骤：$L \rightarrow A \rightarrow S&#39; \rightarrow S$。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$S&#39;_{t_1 t_2} = S_{t_1 t_2} / \sqrt{d_{out}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$A_{t_1 t_2} = \frac{\exp(S&#39;_{t_1 t_2})}{\mathbf{1}_{t_2&#39;&#39;} \exp(S&#39;_{t_1 t_2&#39;&#39;})}$ (Softmax)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
&lt;p&gt;我们想求 $\frac{\partial L}{\partial S_{t_1 t_2}}$ (一个特定的 $S$ 元素)。$S_{t_1 t_2}$ 通过 $S&#39;_{t_1 t_2}$ 影响第 $t_1$ 行的所有 $A$ 元素（即 $A_{t_1 t_2&#39;}$，其中 $t_2&#39;$ 是该行的任一列）。&lt;/p&gt;
$$G^S_{t_1 t_2} 
    = \frac{\partial L}{\partial S_{t_1 t_2}} 
    = \frac{\partial L}{\partial A_{t_1&#39; t_2&#39;}} \frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S_{t_1 t_2}}$$
&lt;p&gt;(注意：Softmax 是逐行应用的，所以 $S_{t_1 t_2}$ 只影响 $A_{t_1 :}$，这就是为什么求和中没有 $t_1&#39;$。)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算局部梯度（$\frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S_{t_1 t_2}}$）：&lt;/p&gt;
&lt;p&gt;我们需要再次使用链式法则：$\frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S_{t_1 t_2}} = \sum_{t_2&#39;&#39;} \frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S&#39;_{t_1&#39;&#39; t_2&#39;&#39;}} \frac{\partial S&#39;_{t_1&#39;&#39; t_2&#39;&#39;}}{\partial S_{t_1 t_2}}$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缩放梯度：&lt;/strong&gt; $\frac{\partial S&#39;_{t_1&#39;&#39; t_2&#39;&#39;}}{\partial S_{t_1 t_2}} = \frac{\partial (S_{t_1&#39;&#39; t_2&#39;&#39;} / \sqrt{d_{out}})}{\partial S_{t_1 t_2}} = \frac{1}{\sqrt{d_{out}}} \delta_{t_2&#39;&#39; t_2} \delta_{t_{1}&#39;&#39;t_{1}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Softmax 雅可比矩阵：&lt;/strong&gt; $\frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S&#39;_{t_1&#39;&#39; t_2&#39;&#39;}}$
因为 $A_{t_1 t_2}$ 是个softmax操作，所以这里要对softmax进行求导。可以把分子和分母分开处理。
令 $\sigma_{t_{1}}=\mathbf{1}_{t_{2}}\exp(S&#39;_{t_{1}t_{2}})$
$\frac{\partial\sigma_{t_{1}}}{\partial S&#39;_{t_{1}&#39;t_{2}&#39;}}=\mathbf{1}_{t_{2}}\exp(S&#39;_{t_{1}t_{2}})\delta_{t_{1}t_{1}&#39;}\delta_{t_{2}t_{2}&#39;}=\mathbf{1}_{t_{2}&#39;}\exp(S&#39;_{t_{1}t_{2}&#39;})\delta_{t_{1}t_{1}&#39;}=\exp(S&#39;_{t_{1}t_{2}&#39;})\delta_{t_{1}t_{1}&#39;}$
代入计算公式有，
&lt;/p&gt;
$$\begin{aligned}\frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S&#39;_{t_1&#39;&#39; t_2&#39;&#39;}}&amp;=\frac{1}{\sigma_{t_{1}&#39;}^2}\left( \frac{\partial\exp(S_{t_{1}&#39;t_{2}&#39;}&#39;)}{\partial S&#39;_{t_{1}&#39;&#39;t_{2}&#39;&#39;}}\sigma_{t_{1}&#39;}-\exp(S_{t_{1}&#39;t_{2}&#39;}&#39;) \frac{\partial \sigma_{t_{1}&#39;}}{\partial S_{t_{1}&#39;&#39;t_{2}&#39;&#39;}}\right)\\&amp;=\frac{1}{\sigma_{t_{1}&#39;}^2}\left(\exp(S_{t_{1}&#39;t_{2}&#39;}&#39;)\delta_{t_{1}&#39;t_{1}&#39;&#39;}\delta_{t_{2}&#39;t_{2}&#39;&#39;}\sigma_{t_{1}&#39;}-\exp(S_{t_{1}&#39;t_{2}&#39;}&#39;)\exp(S&#39;_{t_{1}&#39;t_{2}&#39;&#39;})\delta_{t_{1}&#39;t_{1}&#39;&#39;}\right)\\&amp;=\delta_{t_{1}&#39;t_{1}&#39;&#39;}\left(A_{t_1&#39; t_2&#39;}\delta_{t_{2}&#39;t_{2}&#39;&#39;}-A_{t_1&#39; t_2&#39;}A_{t_1&#39; t_2&#39;&#39;}\right)\end{aligned}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回 (1) 和 (2) 到局部梯度：&lt;/p&gt;
$$\frac{\partial A_{t_1&#39; t_2&#39;}}{\partial S_{t_1 t_2}} =  A_{t_1&#39; t_2&#39;} (\delta_{t_2&#39; t_2} - A_{t_1&#39; t_2})  \left( \frac{1}{\sqrt{d_{out}}} \delta_{t_1&#39; t_1} \right)$$
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回 $G^S$ 的推导：&lt;/p&gt;
$$G^S_{t_1 t_2} = G^A_{t_1&#39; t_2&#39;} A_{t_1&#39; t_2&#39;} (\delta_{t_2&#39; t_2} - A_{t_1&#39; t_2})  \left( \frac{1}{\sqrt{d_{out}}} \delta_{t_1&#39; t_1} \right)$$
$$G^S_{t_1 t_2} = \frac{1}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2&#39;} A_{t_1 t_2&#39;} \delta_{t_2&#39; t_2} - G^A_{t_1 t_2&#39;} A_{t_1 t_2&#39;} A_{t_1 t_2} \right)$$
$$G^S_{t_1 t_2} = \frac{1}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} A_{t_1 t_2} - A_{t_1 t_2}G^A_{t_1 t_2&#39;} A_{t_1 t_2&#39;} \right)$$
$$G^S_{t_1 t_2} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} - G^A_{t_1 t_2&#39;} A_{t_1 t_2&#39;} \right)$$
&lt;p&gt;(其中 $t_2&#39;$ 是在 $G^A$ 和 $A$ 的逐元素乘积上求和的哑索引。)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.3：计算 $\frac{\partial L}{\partial Q}$ (即 $G^Q$)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则： (现在我们使用 $G^S$ 作为上游梯度)&lt;/p&gt;
$$G^Q_{t_1 j} = \frac{\partial L}{\partial Q_{t_1 j}} = \frac{\partial L}{\partial S_{t_1&#39; t_2&#39;}} \frac{\partial S_{t_1&#39; t_2&#39;}}{\partial Q_{t_1 j}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial S_{t_1&#39; t_2&#39;}}{\partial Q_{t_1 j}} = \frac{\partial (Q_{t_1&#39; j&#39;} K_{t_2&#39; j&#39;})}{\partial Q_{t_1 j}} = \delta_{t_1&#39; t_1} K_{t_2&#39; j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$G^Q_{t_1 j} = G^S_{t_1 t_2} K_{t_2 j}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.4：计算 $\frac{\partial L}{\partial K}$ (即 $G^K$)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
$$G^K_{t_2 j} = \frac{\partial L}{\partial K_{t_2 j}} = \frac{\partial L}{\partial S_{t_1&#39; t_2&#39;}} \frac{\partial S_{t_1&#39; t_2&#39;}}{\partial K_{t_2 j}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial S_{t_1&#39; t_2&#39;}}{\partial K_{t_2 j}} = \frac{\partial (Q_{t_1&#39; j&#39;} K_{t_2&#39; j&#39;})}{\partial K_{t_2 j}} = Q_{t_1&#39; j} \delta_{t_2&#39; t_2}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$G^K_{t_2 j} = G^S_{t_1 t_2} Q_{t_1 j}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.5：计算 $\frac{\partial L}{\partial W^Q}$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;前向方程：&lt;/strong&gt; $Q_{t_1 j} = X_{t_1 i} W^Q_{ji}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
$$\frac{\partial L}{\partial W^Q_{ji}} = \frac{\partial L}{\partial Q_{t_1&#39; j&#39;}} \frac{\partial Q_{t_1&#39; j&#39;}}{\partial W^Q_{ji}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计算局部梯度：&lt;/strong&gt; $\frac{\partial Q_{t_1&#39; j&#39;}}{\partial W^Q_{ji}} = \frac{\partial (X_{t_1&#39; i&#39;} W^Q_{j&#39; i&#39;})}{\partial W^Q_{ji}} = X_{t_1&#39; i} \delta_{j&#39; j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$\frac{\partial L}{\partial W^Q_{ji}} = G^Q_{t_1 j} X_{t_1 i}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;步骤 2.6：计算 $\frac{\partial L}{\partial W^K}$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;前向方程： $K_{t_2 j} = X_{t_2 k} W^K_{jk}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用链式法则：&lt;/p&gt;
$$\frac{\partial L}{\partial W^K_{jk}} =  \frac{\partial L}{\partial K_{t_2&#39; j&#39;}} \frac{\partial K_{t_2&#39; j&#39;}}{\partial W^K_{jk}}$$
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算局部梯度： $\frac{\partial K_{t_2&#39; j&#39;}}{\partial W^K_{jk}} = \frac{\partial (X_{t_2&#39; k&#39;} W^K_{j&#39; k&#39;})}{\partial W^K_{jk}} = X_{t_2&#39; k} \delta_{j&#39; j}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;代回（并使用爱因斯坦约定）：&lt;/p&gt;
$$\frac{\partial L}{\partial W^K_{jk}} = G^K_{t_2 j} X_{t_2 k}$$
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;$W^Q$ 和 $W^K$ 梯度总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 &lt;strong&gt;2.3&lt;/strong&gt; 代入 &lt;strong&gt;2.5&lt;/strong&gt;，得到 $W^Q$ 的最终梯度：&lt;/p&gt;
$$\frac{\partial L}{\partial W^Q_{ji}} = (G^S_{t_1 t_2} K_{t_2 j}) X_{t_1 i}$$
&lt;p&gt;将 &lt;strong&gt;2.4&lt;/strong&gt; 代入 &lt;strong&gt;2.6&lt;/strong&gt;，得到 $W^K$ 的最终梯度：&lt;/p&gt;
$$\frac{\partial L}{\partial W^K_{jk}} = (G^S_{t_1 t_2} Q_{t_1 j}) X_{t_2 k}$$
&lt;p&gt;其中 $G^S_{t_1 t_2}$ 由&lt;strong&gt;步骤 2.2&lt;/strong&gt; 定义, 如下所示：
&lt;/p&gt;
$$
G^S_{t_1 t_2} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} - G^A_{t_1 t_2&#39;} A_{t_1 t_2&#39;} \right)
$$
&lt;hr&gt;
&lt;h4 id=&#34;第3部分数据梯度的推导&#34;&gt;第3部分：数据梯度的推导
&lt;/h4&gt;&lt;hr&gt;
&lt;h3 id=&#34;最终梯度总结&#34;&gt;最终梯度总结
&lt;/h3&gt;&lt;p&gt;以下是损失 $L$ 对三个权重矩阵的完整梯度，其中 $G^S$ 已被明确推导。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Value 权重梯度 ($W^V$):&lt;/p&gt;
$$\frac{\partial L}{\partial W^V_{jk}} = \left( \frac{\partial L}{\partial Y_{t_1 j}} A_{t_1 t_2} \right) X_{t_2 k}$$
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;公式解释：Value 权重梯度是误差信号和注意力权重在 $t_{1}$ 上的内积，也就是计算Value在查询token维度上对误差信号有多大贡献，即分配给Value的误差。然后再和输入嵌入在 $t_{2}$ 上的内积，计算此时被 $X_{t_{2}k}$ 激活的信号。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Query 权重梯度 ($W^Q$):&lt;/p&gt;
$$\frac{\partial L}{\partial W^Q_{ji}} = \left( \frac{\partial L}{\partial S_{t_1 t_2}} K_{t_2 j} \right) X_{t_1 i}$$
&lt;p&gt;
公式解释：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Key 权重梯度 ($W^K$):&lt;/p&gt;
$$\frac{\partial L}{\partial W^K_{jk}} = \left( \frac{\partial L}{\partial S_{t_1 t_2}} Q_{t_1 j} \right) X_{t_2 k}$$
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中，关键的中间梯度 $\frac{\partial L}{\partial S_{t_1 t_2}}$ (即 $G^S$) 定义为：&lt;/p&gt;
$$\frac{\partial L}{\partial S_{t_1 t_2}} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( \frac{\partial L}{\partial A_{t_1 t_2}} - \sum_{t_2&#39;} \frac{\partial L}{\partial A_{t_1 t_2&#39;}} A_{t_1 t_2&#39;} \right)$$
&lt;blockquote&gt;
&lt;p&gt;公式解释: 注意力权重对损失的贡献既要看直接贡献也要看平均贡献。括号内的求和实际上就是求平均贡献，是一个相对标准，它奖励那些表现偏离“平均水平”的得分，并惩罚那些表现不如平均水平的得分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而 $\frac{\partial L}{\partial A_{t_1 t_2}}$ (即 $G^A$) 定义为：&lt;/p&gt;
$$\frac{\partial L}{\partial A_{t_1 t_2}} = \frac{\partial L}{\partial Y_{t_1 j}} V_{t_2 j}$$
&lt;h3 id=&#34;梯度公式的pytorch验证&#34;&gt;梯度公式的pytorch验证
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;  1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;  9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 42
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 43
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 44
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 45
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 46
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 47
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 48
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 49
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 50
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 51
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 52
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 53
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 54
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 55
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 56
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 57
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 58
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 59
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 60
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 61
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 62
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 63
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 64
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 65
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 66
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 67
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 68
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 69
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 70
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 71
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 72
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 73
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 74
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 75
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 76
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 77
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 78
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 79
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 80
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 81
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 82
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 83
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 84
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 85
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 86
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 87
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 88
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 89
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 90
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 91
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 92
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 93
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 94
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 95
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 96
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 97
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 98
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 99
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;100
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;101
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;102
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;103
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;104
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;105
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;106
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;107
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;108
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;109
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;110
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;111
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;112
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;113
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;114
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;115
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;116
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;117
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;118
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;119
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;120
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;121
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;122
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;123
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;124
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;125
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;126
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;127
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;128
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;129
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;130
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.testing&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 导入测试库&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 步骤 1: 修改 SelfAttention 以存储 q, k, v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 我们必须存储 q, k, v 才能在之后访问它们来计算梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SelfAttention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;qkv_bias&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 为所有中间张量添加占位符&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# S&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# A&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context_vecs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# 计算 q, k, v 并 *保存* 它们&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# d_k (d_out) 的缩放因子&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# S = Q @ K.T&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# A = softmax(S / scale)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_scores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;c1&#34;&gt;# Y = A @ V&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context_vecs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context_vecs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 步骤 2: 设置并运行前向和后向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 设置输入维度和输出维度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建SelfAttention对象&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SelfAttention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;d_in&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;d_out&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 为了可复现性，固定随机种子&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manual_seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 创建输入张量和上游梯度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;requires_grad&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (B, S_in, d_in)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_grad&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (B, S_out, d_out)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 运行前向和后向过程&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 这会为 W_v.weight, W_q.weight, W_k.weight 自动填充 .grad 属性&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 步骤 3: 按照你提供的公式手动计算梯度并进行验证&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------------------------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--- 梯度验证开始 ---&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 索引约定:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# b: batch (10)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# q: query token 序列 (10)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# v: key/value token 序列 (10)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# i: d_in (10)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# o: d_out (20)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3.A: 计算中间梯度 G^A 和 G^S&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# G^A = dL/dA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 公式: dL/dA[q,v] = dL/dY[q,o] * V[v,o]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# einsum: (bqo, bvo) -&amp;gt; bqv&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;grad_A&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;einsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bqo, bvo -&amp;gt; bqv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# G^S = dL/dS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 这是 softmax 的反向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 公式: dL/dS = (A / scale) * (dL/dA - sum(dL/dA * A))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# sum(dL/dA * A)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# einsum: (bqv, bqv) -&amp;gt; bq&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;row_dot_sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;einsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bqv, bqv -&amp;gt; bq&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;grad_A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unsqueeze&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 形状变为 (b,q,1)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# dL/dS&amp;#39; = A * (dL/dA - sum(dL/dA * A))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# (bqv) * ((bqv) - (bq,1)) -&amp;gt; (bqv)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;grad_S_prime&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_A&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;row_dot_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# dL/dS = dL/dS&amp;#39; / scale&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# (bqv)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;grad_S&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;grad_S_prime&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3.B: 验证 Value 权重梯度 (W^V)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 公式: dL/dW_v[o,i] = (dL/dY[q,o] * A[q,v]) * X[v,i]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# (注意你的公式中 j-&amp;gt;o, k-&amp;gt;i, t1-&amp;gt;q, t2-&amp;gt;v)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# einsum: (bqo, bqv, bvi) -&amp;gt; oi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;grad_Wv_manual&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;einsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bqo, bqv, bvi -&amp;gt; oi&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;y_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;attn_weights&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;assert_close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_Wv_manual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_v 梯度计算正确&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;AssertionError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_v 梯度计算错误:&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3.C: 验证 Query 权重梯度 (W^Q)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 公式: dL/dW_q[o,i] = (dL/dS[q,v] * K[v,o]) * X[q,i]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# (注意你的公式中 j-&amp;gt;o, i-&amp;gt;i, t1-&amp;gt;q, t2-&amp;gt;v)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# einsum: (bqv, bvo, bqi) -&amp;gt; oi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;grad_Wq_manual&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;einsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bqv, bvo, bqi -&amp;gt; oi&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;grad_S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;assert_close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_Wq_manual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_q&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_q 梯度计算正确&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;AssertionError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_q 梯度计算错误:&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3.D: 验证 Key 权重梯度 (W^K)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ---------------------------------&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 公式: dL/dW_k[o,i] = (dL/dS[q,v] * Q[q,o]) * X[v,i]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# (注意你的公式中 j-&amp;gt;o, k-&amp;gt;i, t1-&amp;gt;q, t2-&amp;gt;v)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# einsum: (bqv, bqo, bvi) -&amp;gt; oi&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;grad_Wk_manual&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;einsum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;bqv, bqo, bvi -&amp;gt; oi&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;grad_S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;assert_close&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad_Wk_manual&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;attention&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W_k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_k 梯度计算正确&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;except&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;AssertionError&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;W_k 梯度计算错误:&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--- 梯度验证完成 ---&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;多头注意力&#34;&gt;多头注意力
&lt;/h2&gt;&lt;p&gt;代码部分&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;torch.nn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;nn&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;MultiHeadSelfAttention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# input dimension&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# key and query dimension&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# value dimension&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# number of heads, for each head, dim_* = dim_* // num_heads&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nb&#34;&gt;super&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MultiHeadSelfAttention&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;dim_k and dim_v must be multiple of num_heads&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Linear&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bias&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_norm_fact&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;forward&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# x: tensor of shape (batch, n, dim_in)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;assert&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_in&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_heads&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dk&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# dim_k of each head&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dv&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# dim_v of each head&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (batch, nh, n, dk)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dk&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (batch, nh, n, dk)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;linear_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# (batch, nh, n, dv)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_norm_fact&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# batch, nh, n, n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;dist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;softmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dim&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# batch, nh, n, n&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;att&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matmul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# batch, nh, n, dv&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;n&#34;&gt;att&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;att&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transpose&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dim_v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# batch, n, dim_v&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;att&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这正是&lt;strong&gt;多头自注意力 (Multi-Head Self-Attention, MHSA)&lt;/strong&gt; 的一个高效实现。&lt;/p&gt;
&lt;p&gt;与单头自注意力一样，&lt;code&gt;softmax&lt;/code&gt; 的存在使其成为一个&lt;strong&gt;非线性&lt;/strong&gt;操作，因此我们不能将其表示为&lt;strong&gt;单一的&lt;/strong&gt;静态张量缩并。&lt;/p&gt;
&lt;p&gt;然而，我们可以将代码中的每一步——特别是 &lt;code&gt;reshape&lt;/code&gt; 和 &lt;code&gt;transpose&lt;/code&gt; 操作——用更清晰的爱因斯坦求和约定 (Einstein Summation Convention) 来表示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;索引和张量定义&lt;/strong&gt;
我们引入一个新的索引 &lt;code&gt;h&lt;/code&gt; 来代表&lt;strong&gt;注意力头 (Head)&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$b$: Batch (批次) 索引&lt;/li&gt;
&lt;li&gt;$t_1, t_2$: Token/序列 (Sequence) 索引 (基数都为 $n$)&lt;/li&gt;
&lt;li&gt;$i, k$: 输入特征维度 ($dim\_in$) 的索引&lt;/li&gt;
&lt;li&gt;$h$: 注意力头索引 (基数 &lt;code&gt;num_heads&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;$j$: 键/查询 (Key/Query) 特征维度 (基数 &lt;code&gt;dk = dim_k // num_heads&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;$m$: 值 (Value) 特征维度 (基数 &lt;code&gt;dv = dim_v // num_heads&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;输入张量：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Input $X$:&lt;/strong&gt; $X_{bti}$ (对应 &lt;code&gt;x&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;权重张量 (逻辑上的)：
代码中的 nn.Linear(dim_in, dim_k) 只是一个计算上的融合。在逻辑上，它代表了 num_heads 个独立的权重矩阵。我们可以将这些权重张量定义为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Query Weights $W_Q$:&lt;/strong&gt; $W^Q_{hji}$ (形状 &lt;code&gt;nh, dk, dim_in&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key Weights $W_K$:&lt;/strong&gt; $W^K_{hji}$ (形状 &lt;code&gt;nh, dk, dim_in&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value Weights $W_V$:&lt;/strong&gt; $W^V_{hmi}$ (形状 &lt;code&gt;nh, dv, dim_in&lt;/code&gt;)
(注：代码中 &lt;code&gt;self.linear_q.weight&lt;/code&gt; 的实际形状是 &lt;code&gt;(dim_k, dim_in)&lt;/code&gt;，即 &lt;code&gt;(nh*dk, dim_in)&lt;/code&gt;。$W^Q_{hji}$ 是它在逻辑上的 &lt;code&gt;(nh, dk, dim_in)&lt;/code&gt; 重塑。)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;张量化步骤&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;q, k, v 的计算 (线性)
代码中的 linear_q(x).reshape(&amp;hellip;).transpose(&amp;hellip;) 这一整行操作，在张量表示法中只是一个单独的、简洁的张量缩并：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Query:&lt;/strong&gt; $Q_{bht_1 j} = X_{bt_1 i} W^Q_{hji}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key:&lt;/strong&gt; $K_{bht_2 j} = X_{bt_2 i} W^K_{hji}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Value:&lt;/strong&gt; $V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$
&lt;em&gt;分析：&lt;/em&gt; 以 $Q$ 为例， $X$ (&lt;code&gt;b, t1, i&lt;/code&gt;) 和 $W^Q$ (&lt;code&gt;h, j, i&lt;/code&gt;) 在 &lt;code&gt;i&lt;/code&gt; 维度上缩并，自由索引 $b, h, t_1, j$ 保留下来，正好得到代码中 $q$ 的形状 &lt;code&gt;(batch, nh, n, dk)&lt;/code&gt;。&lt;code&gt;reshape&lt;/code&gt; 和 &lt;code&gt;transpose&lt;/code&gt; 只是 PyTorch 实现这一逻辑所必需的步骤。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;dist 的计算 (线性部分)
这是 $Q$ 和 $K$ 的批量矩阵乘法，在 $j$ (即 dk) 维度上缩并：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Scores:&lt;/strong&gt; $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scaled Scores:&lt;/strong&gt; $S&#39;_{bht_1 t_2} = \frac{S_{bht_1 t_2}}{\sqrt{d_k}}$ (其中 $d_k$ = &lt;code&gt;dk&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;dist 的计算 (非线性)
softmax 沿着 $t_2$ 维度（代码中的 dim=-1）进行：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Weights:&lt;/strong&gt; $A_{bht_1 t_2} = \text{softmax}_{t_2}(S&#39;_{bht_1 t_2})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;att 的计算 (线性)
这是注意力权重 $A$ 和值 $V$ 的批量矩阵乘法，在 $t_2$ 维度上缩并：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Head Context:&lt;/strong&gt; $Y&#39;_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$
&lt;em&gt;分析：&lt;/em&gt; 此时我们得到的张量 $Y&#39;$ 形状为 &lt;code&gt;(batch, nh, n, dv)&lt;/code&gt;，对应代码中 &lt;code&gt;matmul(dist, v)&lt;/code&gt; 的直接输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;att 的重塑 (Concat)
代码中的最后一步 att.transpose(1, 2).reshape(batch, n, self.dim_v) 是将所有头的上下文向量拼接 (concatenate) 起来。
在张量表示法中，这是将 &lt;code&gt;h&lt;/code&gt; (头) 和 &lt;code&gt;m&lt;/code&gt; (dv) 两个维度“压平”成一个单一的 $dim\_v$ 维度。如果 $Y_{bt_1 l}$ 是最终输出 (其中 $l$ 是 $dim\_v$ 索引)，那么：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Final Output:&lt;/strong&gt; $Y_{bt_1 l} = Y&#39;_{bht_1 m}$ (其中 $l = h \cdot d_v + m$)
这在张量表示中通常被理解为维度的重塑，即 $Y&#39;_{bht_1 m}$ (形状 &lt;code&gt;b, h, t1, m&lt;/code&gt;) 被重塑为 $Y_{bt_1 (hm)}$ (形状 &lt;code&gt;b, t1, [h*m]&lt;/code&gt;)。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;总结：组合的张量形式&lt;/strong&gt;
我们可以将这些步骤（除 &lt;code&gt;softmax&lt;/code&gt; 外）代入，得到一个更完整的视图：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算分数 (Scores):
$$S&#39;_{bht_1 t_2} = \frac{(X_{bt_1 i} W^Q_{hji}) (X_{bt_2 k} W^K_{hjk})}{\sqrt{d_k}}$$
(这里我们用 $i$ 和 $k$ 作为 dim_in 的哑索引以示区分)&lt;/li&gt;
&lt;li&gt;应用非线性 (Softmax):
$$A_{bht_1 t_2} = \text{softmax}_{t_2}(S&#39;_{bht_1 t_2})$$&lt;/li&gt;
&lt;li&gt;计算头部上下文 (Head Contexts):
$$Y&#39;_{bht_1 m} = A_{bht_1 t_2} (X_{bt_2 i} W^V_{hmi})$$&lt;/li&gt;
&lt;li&gt;拼接头部 (Concatenate Heads):
$Y_{bt_1 l}$ (最终输出) 是 $Y&#39;_{bht_1 m}$ 张量在 $h$ 和 $m$ 维度上的重塑/拼接。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;梯度推导&#34;&gt;梯度推导
&lt;/h3&gt;&lt;p&gt;我们将使用反向传播的链式法则。我们的目标是求出标量损失函数 $L$ 相对于三个权重张量 $W^Q$, $W^K$, $W^V$ 的梯度。&lt;/p&gt;
&lt;h3 id=&#34;1-符号约定&#34;&gt;1. 符号约定
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;标量损失 (Scalar Loss):&lt;/strong&gt; $L$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;梯度符号:&lt;/strong&gt; $\bar{Z} = \frac{\partial L}{\partial Z}$。例如，$\bar{W}^Q_{hji}$ 是 $L$ 对 $W^Q_{hji}$ 的梯度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;索引 (Indices):&lt;/strong&gt; 与上一条回复相同：
&lt;ul&gt;
&lt;li&gt;$b$: Batch, $t_1, t_2$: Token, $i$: $d_{in}$, $h$: Head&lt;/li&gt;
&lt;li&gt;$j$: $d_k$ (K/Q dim), $m$: $d_v$ (V dim)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缩放因子:&lt;/strong&gt; $\alpha = 1 / \sqrt{d_k}$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-前向传播回顾&#34;&gt;2. 前向传播（回顾）
&lt;/h3&gt;&lt;p&gt;我们需要前向传播的方程来计算反向传播：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Q, K, V:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;$Q_{bht_1 j} = X_{bt_1 i} W^Q_{hji}$&lt;/li&gt;
&lt;li&gt;$K_{bht_2 j} = X_{bt_2 i} W^K_{hji}$&lt;/li&gt;
&lt;li&gt;$V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scores:&lt;/strong&gt; $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scaled Scores:&lt;/strong&gt; $S&#39;_{bht_1 t_2} = S_{bht_1 t_2} \cdot \alpha$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weights:&lt;/strong&gt; $A_{bht_1 t_2} = \text{softmax}_{t_2}(S&#39;_{bht_1 t_2})$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Head Context:&lt;/strong&gt; $Y&#39;_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Final Output (Reshape):&lt;/strong&gt; $Y_{bt_1 l} = \text{Reshape}(Y&#39;_{bht_1 m})$ (其中 $l$ 是 $h$ 和 $m$ 的组合)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;3-反向传播梯度计算&#34;&gt;3. 反向传播（梯度计算）
&lt;/h3&gt;&lt;p&gt;我们假设我们已经收到了来自模型后续层或损失函数的&lt;strong&gt;上游梯度&lt;/strong&gt;，即 $\bar{Y}_{bt_1 l}$。
&lt;strong&gt;步骤 0：梯度的 &amp;ldquo;Un-Reshape&amp;rdquo;&lt;/strong&gt;
首先，我们需要将上游梯度 $\bar{Y}_{bt_1 l}$ 恢复到拼接 (concatenate) 之前的形状：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{Y}&#39;_{bht_1 m} = \text{Un-Reshape}(\bar{Y}_{bt_1 l})$
现在我们有了 $\bar{Y}&#39;_{bht_1 m}$，我们可以开始计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;a-barwv-value-权重的梯度&#34;&gt;A. $\bar{W}^V$ (Value 权重的梯度)
&lt;/h4&gt;&lt;p&gt;这是最简单的路径，因为它不经过 softmax。&lt;/p&gt;
&lt;p&gt;步骤 A1：计算 $\bar{A}$ 和 $\bar{V}$&lt;/p&gt;
&lt;p&gt;我们从 $Y&#39;_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$ 开始，对 $A$ 和 $V$ 求偏导：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{A}_{bht_1 t_2}$&lt;/strong&gt; (对 $A$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{A}_{bht_1 t_2} = \bar{Y}&#39;_{bht_1 m} V_{bht_2 m}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{V}_{bht_2 m}$&lt;/strong&gt; (对 $V$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{V}_{bht_2 m} = A_{bht_1 t_2} \bar{Y}&#39;_{bht_1 m}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤 A2：计算 $\bar{W}^V$&lt;/p&gt;
&lt;p&gt;我们从 $V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$ 和 $\bar{V}_{bht_2 m}$ 开始：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^V_{hmi}$&lt;/strong&gt; (对 $W^V$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{W}^V_{hmi} = \bar{V}_{bht_2 m} X_{bt_2 i}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;$\bar{W}^V$ 最终公式:&lt;/p&gt;
$$\bar{W}^V_{hmi} = (A_{bht_1 t_2} \bar{Y}&#39;_{bht_1 m}) X_{bt_2 i}$$
&lt;p&gt;(对 $b, t_1, t_2$ 求和)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;公式说明：损失函数 $L$ 对 $W^{V}$ 的梯度。自由指标是 $hmi$ ，说明梯度依赖不同的注意力头、值嵌入、输入嵌入进行区分。
$\bar{Y}&#39;_{bht_1 m}$ 传递了上一层的误差信号（前向传播的下一层），$A_{bht_1 t_2}$ 是注意力分数，$X_{bt_2 i}$ 是值数据。先计算了误差信号和注意力分数在查询token角度的相似程度 $\bar{V}_{bht_2 m}$，也就是分配给 $V_{bht_2 m}$ 的&lt;strong&gt;误差权重&lt;/strong&gt;。然后比较了$\bar{V}_{bht_2 m}$ 和 $X_{bt_2 i}$ 之间在批次、值token角度上的相似度&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;b-barwq-和-barwk-query-和-key-权重的梯度&#34;&gt;B. $\bar{W}^Q$ 和 $\bar{W}^K$ (Query 和 Key 权重的梯度)
&lt;/h4&gt;&lt;p&gt;这条路径更长，因为它必须穿过 $\bar{A}$ 和 softmax。&lt;/p&gt;
&lt;p&gt;步骤 B1：计算 $\bar{S}&#39;$ (Softmax 的梯度)&lt;/p&gt;
&lt;p&gt;这是最复杂的一步。我们需要 $\bar{A}_{bht_1 t_2}$ (已在 A1 中求得)。Softmax 的导数是一个雅可比矩阵，但在张量表示法中，其反向传播可以写为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先，计算每行（$t_1$）的“点积”：$C_{bht_1} = \bar{A}_{bht_1 t_2} A_{bht_1 t_2}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;然后， $\bar{S}&#39;$ (对 $S&#39;$ 的梯度) 是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{S}&#39;_{bht_1 t_2} = A_{bht_1 t_2} (\bar{A}_{bht_1 t_2} - C_{bht_1})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤 B2：计算 $\bar{S}$ (缩放的梯度)&lt;/p&gt;
&lt;p&gt;从 $S&#39;_{bht_1 t_2} = S_{bht_1 t_2} \cdot \alpha$ 开始：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{S}_{bht_1 t_2} = \bar{S}&#39;_{bht_1 t_2} \cdot \alpha$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤 B3：计算 $\bar{Q}$ 和 $\bar{K}$&lt;/p&gt;
&lt;p&gt;从 $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$ 和 $\bar{S}_{bht_1 t_2}$ 开始：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{Q}_{bht_1 j}$&lt;/strong&gt; (对 $Q$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{Q}_{bht_1 j} = \bar{S}_{bht_1 t_2} K_{bht_2 j}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{K}_{bht_2 j}$&lt;/strong&gt; (对 $K$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{K}_{bht_2 j} = \bar{S}_{bht_1 t_2} Q_{bht_1 j}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;步骤 B4：计算 $\bar{W}^Q$ 和 $\bar{W}^K$&lt;/p&gt;
&lt;p&gt;最后，我们使用 $\bar{Q}$, $\bar{K}$ 和 $X$：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^Q_{hji}$&lt;/strong&gt; (对 $W^Q$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{W}^Q_{hji} = \bar{Q}_{bht_1 j} X_{bt_1 i}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^K_{hji}$&lt;/strong&gt; (对 $W^K$ 的梯度):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\bar{W}^K_{hji} = \bar{K}_{bht_2 j} X_{bt_2 i}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;4-总结最终梯度公式&#34;&gt;4. 总结：最终梯度公式
&lt;/h3&gt;&lt;p&gt;将所有步骤代入，我们得到三个权重矩阵的最终梯度：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^V_{hmi} = (A_{bht_1 t_2} \bar{Y}&#39;_{bht_1 m}) X_{bt_2 i}$&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^Q_{hji} = ((\bar{S}&#39;_{bht_1 t_2} \alpha) K_{bht_2 j}) X_{bt_1 i}$&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;$\bar{W}^K_{hji} = ((\bar{S}&#39;_{bht_1 t_2} \alpha) Q_{bht_1 j}) X_{bt_2 i}$&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中 $\bar{S}&#39;_{bht_1 t_2}$ (来自 softmax 的梯度) 是：&lt;/p&gt;
&lt;p&gt;$\bar{S}&#39;_{bht_1 t_2} = A_{bht_1 t_2} \left( (\bar{Y}&#39;_{bht_1 m} V_{bht_2 m}) - \sum_{t_2&#39;} (\bar{Y}&#39;_{bht_1 m} V_{bht_2&#39; m}) A_{bht_1 t_2&#39;} \right)$&lt;/p&gt;
&lt;p&gt;(注：在所有公式中，重复的索引都表示求和。)&lt;/p&gt;
</description>
        </item>
        <item>
        <title>关于</title>
        <link>http://localhost:1313/hugo_dev/%E5%85%B3%E4%BA%8E/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/%E5%85%B3%E4%BA%8E/</guid>
        <description>&lt;p&gt;This is a test page for i18n support.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索</title>
        <link>http://localhost:1313/hugo_dev/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/search/</guid>
        <description></description>
        </item>
        <item>
        <title>友情链接</title>
        <link>http://localhost:1313/hugo_dev/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/hugo_dev/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;links&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub is the world&amp;#39;s largest software development platform.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://www.typescriptlang.org&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ts-logo-128.jpg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
