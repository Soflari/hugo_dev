<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><script src="/hugo_dev/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=hugo_dev/livereload" data-no-instant defer></script><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="#ä»£ç æ•°å­¦åŒ– è‡ªæ³¨æ„åŠ› ä»£ç éƒ¨åˆ† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import torch import torch.nn as nn class SelfAttention(nn.Module): def __init__(self, d_in, d_out, qkv_bias=False): self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias) def forward(self, x): q = self.W_q(x) k = self.W_k(x) v = self.W_v(x) attn_scores">
<title></title>

<link rel='canonical' href='http://localhost:1313/hugo_dev/p/'>

<link rel="stylesheet" href="/hugo_dev/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css"><meta property='og:title' content="">
<meta property='og:description' content="#ä»£ç æ•°å­¦åŒ– è‡ªæ³¨æ„åŠ› ä»£ç éƒ¨åˆ† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import torch import torch.nn as nn class SelfAttention(nn.Module): def __init__(self, d_in, d_out, qkv_bias=False): self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias) def forward(self, x): q = self.W_q(x) k = self.W_k(x) v = self.W_v(x) attn_scores">
<meta property='og:url' content='http://localhost:1313/hugo_dev/p/'>
<meta property='og:site_name' content='Soflari'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' />
<meta name="twitter:title" content="">
<meta name="twitter:description" content="#ä»£ç æ•°å­¦åŒ– è‡ªæ³¨æ„åŠ› ä»£ç éƒ¨åˆ† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import torch import torch.nn as nn class SelfAttention(nn.Module): def __init__(self, d_in, d_out, qkv_bias=False): self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias) self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias) def forward(self, x): q = self.W_q(x) k = self.W_k(x) v = self.W_v(x) attn_scores">
    <link rel="shortcut icon" href="/favicon.ico" />

  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="åˆ‡æ¢èœå•">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/hugo_dev/">
                
                    
                    
                    
                        
                        <img src="/hugo_dev/img/avatar_hu9278426847092480894.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">ğŸ¥</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/hugo_dev">Soflari</a></h1>
            <h2 class="site-description">æ¬¢è¿ï¼</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/Soflari'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/hugo_dev/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>ä¸»é¡µ</span>
            </a>
        </li>
        
        
        <li >
            <a href='/hugo_dev/%E5%85%B3%E4%BA%8E/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>å…³äº</span>
            </a>
        </li>
        
        
        <li >
            <a href='/hugo_dev/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>å½’æ¡£</span>
            </a>
        </li>
        
        
        <li >
            <a href='/hugo_dev/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>æœç´¢</span>
            </a>
        </li>
        
        
        <li >
            <a href='/hugo_dev/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>å‹æƒ…é“¾æ¥</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">
                    
                        <li id="i18n-switch">  
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                            <select name="language" title="language" onchange="window.location.href = this.selectedOptions[0].value">
                                
                                    <option value="http://localhost:1313/hugo_dev/en/" >English</option>
                                
                                    <option value="http://localhost:1313/hugo_dev/" selected>ç®€ä½“ä¸­æ–‡</option>
                                
                                    <option value="http://localhost:1313/hugo_dev/ar/" >Ø¹Ø±Ø¨ÙŠ</option>
                                
                            </select>
                        </li>
                    
                

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>æš—è‰²æ¨¡å¼</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">ç›®å½•</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#è‡ªæ³¨æ„åŠ›">è‡ªæ³¨æ„åŠ›</a>
      <ol>
        <li><a href="#ä»£ç éƒ¨åˆ†">ä»£ç éƒ¨åˆ†</a></li>
        <li><a href="#å‰å‘è¿‡ç¨‹">å‰å‘è¿‡ç¨‹</a></li>
        <li><a href="#åå‘ä¼ æ’­æ¢¯åº¦æ¨å¯¼">åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦æ¨å¯¼ï¼‰</a>
          <ol>
            <li><a href="#å¼•è¨€å’Œç¬¦å·å®šä¹‰">å¼•è¨€å’Œç¬¦å·å®šä¹‰</a></li>
            <li><a href="#ç¬¬-1-éƒ¨åˆ†wv-value-çš„æ¢¯åº¦æ¨å¯¼">ç¬¬ 1 éƒ¨åˆ†ï¼š (Value) çš„æ¢¯åº¦æ¨å¯¼</a></li>
            <li><a href="#ç¬¬-2-éƒ¨åˆ†wq-query-å’Œ-wk-key-çš„æ¢¯åº¦æ¨å¯¼">ç¬¬ 2 éƒ¨åˆ†ï¼š (Query) å’Œ  (Key) çš„æ¢¯åº¦æ¨å¯¼</a></li>
            <li><a href="#ç¬¬3éƒ¨åˆ†æ•°æ®æ¢¯åº¦çš„æ¨å¯¼">ç¬¬3éƒ¨åˆ†ï¼šæ•°æ®æ¢¯åº¦çš„æ¨å¯¼</a></li>
          </ol>
        </li>
        <li><a href="#æœ€ç»ˆæ¢¯åº¦æ€»ç»“">æœ€ç»ˆæ¢¯åº¦æ€»ç»“</a></li>
        <li><a href="#æ¢¯åº¦å…¬å¼çš„pytorchéªŒè¯">æ¢¯åº¦å…¬å¼çš„pytorchéªŒè¯</a></li>
      </ol>
    </li>
    <li><a href="#å¤šå¤´æ³¨æ„åŠ›">å¤šå¤´æ³¨æ„åŠ›</a>
      <ol>
        <li><a href="#æ¢¯åº¦æ¨å¯¼">æ¢¯åº¦æ¨å¯¼</a></li>
        <li><a href="#1-ç¬¦å·çº¦å®š">1. ç¬¦å·çº¦å®š</a></li>
        <li><a href="#2-å‰å‘ä¼ æ’­å›é¡¾">2. å‰å‘ä¼ æ’­ï¼ˆå›é¡¾ï¼‰</a></li>
        <li><a href="#3-åå‘ä¼ æ’­æ¢¯åº¦è®¡ç®—">3. åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦è®¡ç®—ï¼‰</a>
          <ol>
            <li><a href="#a-barwv-value-æƒé‡çš„æ¢¯åº¦">A.  (Value æƒé‡çš„æ¢¯åº¦)</a></li>
            <li><a href="#b-barwq-å’Œ-barwk-query-å’Œ-key-æƒé‡çš„æ¢¯åº¦">B.  å’Œ  (Query å’Œ Key æƒé‡çš„æ¢¯åº¦)</a></li>
          </ol>
        </li>
        <li><a href="#4-æ€»ç»“æœ€ç»ˆæ¢¯åº¦å…¬å¼">4. æ€»ç»“ï¼šæœ€ç»ˆæ¢¯åº¦å…¬å¼</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/hugo_dev/p/"></a>
        </h2>
    
        
    </div>

    
    
    
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>#ä»£ç æ•°å­¦åŒ–</p>
<hr>
<h2 id="è‡ªæ³¨æ„åŠ›">è‡ªæ³¨æ„åŠ›
</h2><h3 id="ä»£ç éƒ¨åˆ†">ä»£ç éƒ¨åˆ†
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span> 
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> 
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> 
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span> 
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> 
</span></span><span class="line"><span class="cl">	<span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="n">attn_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="n">context_vecs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">context_vecs</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="å‰å‘è¿‡ç¨‹">å‰å‘è¿‡ç¨‹
</h3><p><strong>ç´¢å¼•å’Œå¼ é‡å®šä¹‰</strong></p>
<ul>
<li>$t_1, t_2$: Token/åºåˆ— (Sequence) ç´¢å¼•ã€‚$t_1$ ä»£è¡¨æŸ¥è¯¢ (Query)ï¼Œ$t_2$ ä»£è¡¨é”®/å€¼ (Key/Value)ã€‚</li>
<li>$i, k$: è¾“å…¥ç‰¹å¾ç»´åº¦ ($d\_in$) çš„ç´¢å¼•ã€‚</li>
<li>$j$: è¾“å‡º/å†…éƒ¨ç‰¹å¾ç»´åº¦ ($d\_out$) çš„ç´¢å¼•ã€‚
<strong>è¾“å…¥å¼ é‡ï¼š</strong></li>
<li><strong>Input $X$:</strong> $X_{ti}$ (å¯¹åº”ä»£ç ä¸­çš„ <code>x</code>)</li>
<li><strong>Query Weights $W_Q$:</strong> $W^Q_{ji}$ (å¯¹åº” <code>self.W_q.weight</code>)</li>
<li><strong>Key Weights $W_K$:</strong> $W^K_{jk}$ (å¯¹åº” <code>self.W_k.weight</code>)</li>
<li><strong>Value Weights $W_V$:</strong> $W^V_{jk}$ (å¯¹åº” <code>self.W_v.weight</code>)</li>
<li><strong>Output $Y$:</strong> $Y_{t_1 j}$ (å¯¹åº” <code>context_vecs</code>)</li>
</ul>
<hr>
<ol>
<li><strong><code>q, k, v</code> çš„è®¡ç®— (çº¿æ€§)</strong>
è¿™æ˜¯è¾“å…¥ $X$ å’Œæƒé‡çŸ©é˜µä¹‹é—´çš„å¼ é‡ç¼©å¹¶ï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰ã€‚
<ul>
<li><strong>Query:</strong> $Q_{t_1 j} = X_{t_1 i} W^Q_{ji}$</li>
<li><strong>Key:</strong> $K_{t_2 j} = X_{t_2 k} W^K_{jk}$</li>
<li><strong>Value:</strong> $V_{t_2 j} = X_{t_2 k} W^V_{jk}$
ï¼ˆåœ¨çˆ±å› æ–¯å¦çº¦å®šä¸­ï¼Œé‡å¤çš„ç´¢å¼• $i$ å’Œ $k$ è¡¨ç¤ºåœ¨ $d\_in$ ç»´åº¦ä¸Šæ±‚å’Œã€‚ï¼‰</li>
</ul>
</li>
<li><strong><code>attn_scores</code> çš„è®¡ç®— (çº¿æ€§)</strong>
<code>attn_scores = torch.matmul(q, k.T)</code>ã€‚è¿™æ˜¯ä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼Œå®ƒåœ¨ $j$ (å³ $d\_out$) ç»´åº¦ä¸Šè¿›è¡Œç¼©å¹¶ã€‚
<ul>
<li>$S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$</li>
</ul>
</li>
<li><strong><code>attn_weights</code> çš„è®¡ç®— (éçº¿æ€§)</strong>
<code>attn_weights = torch.softmax(...)</code>ã€‚è¿™ä¸€æ­¥æ˜¯<strong>éçº¿æ€§çš„</strong>ï¼Œä¸èƒ½ç”¨ç®€å•çš„å¼ é‡ç¼©å¹¶è¡¨ç¤ºã€‚æˆ‘ä»¬å°†å…¶å®šä¹‰ä¸ºå‡½æ•° $A = \text{softmax}(S')$ï¼š
<ul>
<li>$S'_{t_1 t_2} = S_{t_1 t_2} / \sqrt{d_{out}}$</li>
<li>$A_{t_1 t_2} = \frac{\exp(S'_{t_1 t_2})}{\mathbf{1}_{t_2'} \exp(S'_{t_1 t_2'})}$
$A_{t_1 t_2}$ æ˜¯æœ€ç»ˆçš„æ³¨æ„åŠ›æƒé‡çŸ©é˜µã€‚</li>
</ul>
</li>
<li><strong><code>context_vecs</code> çš„è®¡ç®— (çº¿æ€§)</strong>
<code>context_vecs = torch.matmul(attn_weights, v)</code>ã€‚è¿™æ˜¯æ³¨æ„åŠ›æƒé‡ $A$ å’Œå€¼ $V$ ä¹‹é—´çš„çŸ©é˜µä¹˜æ³•ã€‚å®ƒåœ¨ $t_2$ ç»´åº¦ï¼ˆåºåˆ—ï¼‰ä¸Šè¿›è¡Œç¼©å¹¶ï¼š
$$Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$$</li>
</ol>
<hr>
<p><strong>æ€»ç»“ï¼šç»„åˆçš„å¼ é‡å½¢å¼</strong>
æˆ‘ä»¬å¯ä»¥æŠŠè¿™äº›æ­¥éª¤ä»£å…¥ï¼Œå¾—åˆ°ä¸€ä¸ªæ›´å®Œæ•´çš„ï¼ˆä½†åˆ†æ­¥çš„ï¼‰å¼ é‡è¡¨ç¤ºï¼š</p>
<ol>
<li>è®¡ç®—åˆ†æ•° (Scores):
$$S_{t_1 t_2} = (X_{t_1 i} W^Q_{ji}) (X_{t_2 k} W^K_{jk})$$</li>
<li>åº”ç”¨éçº¿æ€§ (Softmax):
$$A_{t_1 t_2} = \text{softmax}\left( \frac{S_{t_1 t_2}}{\sqrt{d_{out}}} \right)$$</li>
<li>è®¡ç®—ä¸Šä¸‹æ–‡ (Context):
$$Y_{t_1 j} = A_{t_1 t_2} (X_{t_2 k} W^V_{jk})$$</li>
</ol>
<p>æœ€ç»ˆçš„è¾“å‡º $Y_{t_1 j}$ æ˜¯<strong>æ‰€æœ‰ $t_2$ ä½ç½®çš„å€¼</strong>ï¼ˆç»è¿‡ $W^V$ å˜æ¢åï¼‰çš„<strong>åŠ¨æ€åŠ æƒå’Œ</strong>ï¼Œæƒé‡ $A_{t_1 t_2}$ æ˜¯æ ¹æ®æŸ¥è¯¢å’Œé”®ï¼ˆ$X$ å’Œ $W^Q, W^K$ï¼‰åŠ¨æ€è®¡ç®—å‡ºæ¥çš„ã€‚</p>
<h3 id="åå‘ä¼ æ’­æ¢¯åº¦æ¨å¯¼">åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦æ¨å¯¼ï¼‰
</h3><p>è¿™éå¸¸å…³é”®ï¼Œå› ä¸º $A \rightarrow S$ è¿™ä¸€æ­¥æ˜¯åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰é€šè¿‡ Softmax å‡½æ•°ï¼Œæ˜¯æ•´ä¸ªè¿‡ç¨‹ä¸­æœ€å¤æ‚çš„éƒ¨åˆ†ã€‚</p>
<p>ä¸‹é¢æ˜¯å®Œæ•´çš„ã€åŒ…å«æ‰€æœ‰æ­¥éª¤çš„æ¨å¯¼ã€‚</p>
<h4 id="å¼•è¨€å’Œç¬¦å·å®šä¹‰">å¼•è¨€å’Œç¬¦å·å®šä¹‰
</h4><p>æˆ‘ä»¬å°†éµå¾ªæ‚¨çš„çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®šï¼ˆé‡å¤çš„ç´¢å¼•è¡¨ç¤ºåœ¨è¯¥ç»´åº¦ä¸Šæ±‚å’Œï¼‰ã€‚</p>
<p>å·²çŸ¥ï¼ˆä¸Šæ¸¸æ¢¯åº¦ï¼‰ï¼š</p>
<p>æˆ‘ä»¬å‡è®¾æˆ‘ä»¬å·²ç»æ‹¥æœ‰äº†æŸå¤± $L$ ç›¸å¯¹äºæ³¨æ„åŠ›å±‚æœ€ç»ˆè¾“å‡º $Y$ çš„æ¢¯åº¦ã€‚æˆ‘ä»¬å°†å…¶å®šä¹‰ä¸º $G^Y$ï¼š</p>
$$G^Y_{t_1 j} = \frac{\partial L}{\partial Y_{t_1 j}}$$
<p>ç›®æ ‡ï¼š</p>
<p>æˆ‘ä»¬å¸Œæœ›æ±‚è§£ä»¥ä¸‹ä¸‰ä¸ªæ¢¯åº¦ï¼š</p>
<ol>
<li>
<p>$\frac{\partial L}{\partial W^V_{jk}}$ (Value æƒé‡)</p>
</li>
<li>
<p>$\frac{\partial L}{\partial W^Q_{ji}}$ (Query æƒé‡)</p>
</li>
<li>
<p>$\frac{\partial L}{\partial W^K_{jk}}$ (Key æƒé‡)</p>
</li>
</ol>
<p>ä¸­é—´æ¢¯åº¦ç¬¦å·ï¼š</p>
<p>ä¸ºäº†ä½¿æ¨å¯¼æ›´æ¸…æ™°ï¼Œæˆ‘ä»¬å®šä¹‰ $G^Z = \frac{\partial L}{\partial Z}$ï¼Œè¡¨ç¤º $L$ å¯¹ä»»æ„ä¸­é—´å¼ é‡ $Z$ çš„æ¢¯åº¦ã€‚</p>
<hr>
<h4 id="ç¬¬-1-éƒ¨åˆ†wv-value-çš„æ¢¯åº¦æ¨å¯¼">ç¬¬ 1 éƒ¨åˆ†ï¼š$W^V$ (Value) çš„æ¢¯åº¦æ¨å¯¼
</h4><p>æ­¤è·¯å¾„ä¸ç»è¿‡ Softmaxï¼Œæœ€ä¸ºç›´æ¥ã€‚</p>
<p>åå‘ä¼ æ’­è·¯å¾„æ˜¯ï¼š$L \rightarrow Y \rightarrow V \rightarrow W^V$ã€‚</p>
<p><strong>æ­¥éª¤ 1.1ï¼šè®¡ç®— $\frac{\partial L}{\partial V}$ (å³ $G^V$)</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š æˆ‘ä»¬å¯¹ä¸€ä¸ªç‰¹å®šçš„ $V_{t_2 j}$ æ±‚å¯¼ï¼š</p>
$$G^V_{t_2 j} = \frac{\partial L}{\partial V_{t_2 j}} = \frac{\partial L}{\partial Y_{t_1' j'}} \frac{\partial Y_{t_1' j'}}{\partial V_{t_2 j}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial Y_{t_1' j'}}{\partial V_{t_2 j}} = \frac{\partial (A_{t_1' t_2'} V_{t_2' j'})}{\partial V_{t_2 j}} = A_{t_1' t_2} \delta_{j' j}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$G^V_{t_2 j} = G^Y_{t_1 j} A_{t_1 t_2}$$
</li>
</ul>
<p><strong>æ­¥éª¤ 1.2ï¼šè®¡ç®— $\frac{\partial L}{\partial W^V}$</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $V_{t_2 j} = X_{t_2 k} W^V_{jk}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
$$\frac{\partial L}{\partial W^V_{jk}} = \frac{\partial L}{\partial V_{t_2' j'}} \frac{\partial V_{t_2' j'}}{\partial W^V_{jk}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial V_{t_2' j'}}{\partial W^V_{jk}} = \frac{\partial (X_{t_2' k'} W^V_{j' k'})}{\partial W^V_{jk}} = X_{t_2' k} \delta_{j' j}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$\frac{\partial L}{\partial W^V_{jk}} = G^V_{t_2 j} X_{t_2 k}$$
</li>
</ul>
<p><strong>$W^V$ æ¢¯åº¦æ€»ç»“</strong></p>
<p>å°†æ­¥éª¤ 1.1 ä»£å…¥ 1.2ï¼Œå¾—åˆ° $W^V$ çš„æœ€ç»ˆæ¢¯åº¦ï¼š</p>
$$\frac{\partial L}{\partial W^V_{jk}} = (G^Y_{t_1 j} A_{t_1 t_2}) X_{t_2 k}$$
<hr>
<h4 id="ç¬¬-2-éƒ¨åˆ†wq-query-å’Œ-wk-key-çš„æ¢¯åº¦æ¨å¯¼">ç¬¬ 2 éƒ¨åˆ†ï¼š$W^Q$ (Query) å’Œ $W^K$ (Key) çš„æ¢¯åº¦æ¨å¯¼
</h4><p>æ­¤è·¯å¾„æ˜¯ $L \rightarrow Y \rightarrow A \rightarrow S' \rightarrow S \rightarrow \{Q, K\} \rightarrow \{W^Q, W^K\}$ã€‚</p>
<p><strong>æ­¥éª¤ 2.1ï¼šè®¡ç®— $\frac{\partial L}{\partial A}$ (å³ $G^A$)</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $Y_{t_1 j} = A_{t_1 t_2} V_{t_2 j}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
$$G^A_{t_1 t_2} = \frac{\partial L}{\partial A_{t_1 t_2}} =\frac{\partial L}{\partial Y_{t_1' j'}} \frac{\partial Y_{t_1' j'}}{\partial A_{t_1 t_2}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial Y_{t_1' j'}}{\partial A_{t_1 t_2}} = \frac{\partial (A_{t_1' t_2'} V_{t_2' j'})}{\partial A_{t_1 t_2}} = \delta_{t_1' t_1} V_{t_2 j'}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$G^A_{t_1 t_2} = G^Y_{t_1 j} V_{t_2 j}$$
<p>ï¼ˆè¿™æ˜¯æˆ‘ä»¬ä¸Šä¸€ä¸ªå›ç­”çš„ç»“è®ºï¼Œç°åœ¨å®ƒå°†ä½œä¸º $G^S$ æ¨å¯¼çš„èµ·ç‚¹ã€‚ï¼‰</p>
</li>
</ul>
<p><strong>æ­¥éª¤ 2.2ï¼šè®¡ç®— $\frac{\partial L}{\partial S}$ (å³ $G^S$)</strong></p>
<p>è¿™æ˜¯æœ€å…³é”®çš„æ­¥éª¤ï¼š$L \rightarrow A \rightarrow S' \rightarrow S$ã€‚</p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong></p>
<ol>
<li>
<p>$S'_{t_1 t_2} = S_{t_1 t_2} / \sqrt{d_{out}}$</p>
</li>
<li>
<p>$A_{t_1 t_2} = \frac{\exp(S'_{t_1 t_2})}{\mathbf{1}_{t_2''} \exp(S'_{t_1 t_2''})}$ (Softmax)</p>
</li>
</ol>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
<p>æˆ‘ä»¬æƒ³æ±‚ $\frac{\partial L}{\partial S_{t_1 t_2}}$ (ä¸€ä¸ªç‰¹å®šçš„ $S$ å…ƒç´ )ã€‚$S_{t_1 t_2}$ é€šè¿‡ $S'_{t_1 t_2}$ å½±å“ç¬¬ $t_1$ è¡Œçš„æ‰€æœ‰ $A$ å…ƒç´ ï¼ˆå³ $A_{t_1 t_2'}$ï¼Œå…¶ä¸­ $t_2'$ æ˜¯è¯¥è¡Œçš„ä»»ä¸€åˆ—ï¼‰ã€‚</p>
$$G^S_{t_1 t_2} 
    = \frac{\partial L}{\partial S_{t_1 t_2}} 
    = \frac{\partial L}{\partial A_{t_1' t_2'}} \frac{\partial A_{t_1' t_2'}}{\partial S_{t_1 t_2}}$$
<p>(æ³¨æ„ï¼šSoftmax æ˜¯é€è¡Œåº”ç”¨çš„ï¼Œæ‰€ä»¥ $S_{t_1 t_2}$ åªå½±å“ $A_{t_1 :}$ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ±‚å’Œä¸­æ²¡æœ‰ $t_1'$ã€‚)</p>
</li>
<li>
<p>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼ˆ$\frac{\partial A_{t_1' t_2'}}{\partial S_{t_1 t_2}}$ï¼‰ï¼š</p>
<p>æˆ‘ä»¬éœ€è¦å†æ¬¡ä½¿ç”¨é“¾å¼æ³•åˆ™ï¼š$\frac{\partial A_{t_1' t_2'}}{\partial S_{t_1 t_2}} = \sum_{t_2''} \frac{\partial A_{t_1' t_2'}}{\partial S'_{t_1'' t_2''}} \frac{\partial S'_{t_1'' t_2''}}{\partial S_{t_1 t_2}}$</p>
<ol>
<li>
<p><strong>ç¼©æ”¾æ¢¯åº¦ï¼š</strong> $\frac{\partial S'_{t_1'' t_2''}}{\partial S_{t_1 t_2}} = \frac{\partial (S_{t_1'' t_2''} / \sqrt{d_{out}})}{\partial S_{t_1 t_2}} = \frac{1}{\sqrt{d_{out}}} \delta_{t_2'' t_2} \delta_{t_{1}''t_{1}}$</p>
</li>
<li>
<p><strong>Softmax é›…å¯æ¯”çŸ©é˜µï¼š</strong> $\frac{\partial A_{t_1' t_2'}}{\partial S'_{t_1'' t_2''}}$
å› ä¸º $A_{t_1 t_2}$ æ˜¯ä¸ªsoftmaxæ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œè¦å¯¹softmaxè¿›è¡Œæ±‚å¯¼ã€‚å¯ä»¥æŠŠåˆ†å­å’Œåˆ†æ¯åˆ†å¼€å¤„ç†ã€‚
ä»¤ $\sigma_{t_{1}}=\mathbf{1}_{t_{2}}\exp(S'_{t_{1}t_{2}})$
$\frac{\partial\sigma_{t_{1}}}{\partial S'_{t_{1}'t_{2}'}}=\mathbf{1}_{t_{2}}\exp(S'_{t_{1}t_{2}})\delta_{t_{1}t_{1}'}\delta_{t_{2}t_{2}'}=\mathbf{1}_{t_{2}'}\exp(S'_{t_{1}t_{2}'})\delta_{t_{1}t_{1}'}=\exp(S'_{t_{1}t_{2}'})\delta_{t_{1}t_{1}'}$
ä»£å…¥è®¡ç®—å…¬å¼æœ‰ï¼Œ
</p>
$$\begin{aligned}\frac{\partial A_{t_1' t_2'}}{\partial S'_{t_1'' t_2''}}&=\frac{1}{\sigma_{t_{1}'}^2}\left( \frac{\partial\exp(S_{t_{1}'t_{2}'}')}{\partial S'_{t_{1}''t_{2}''}}\sigma_{t_{1}'}-\exp(S_{t_{1}'t_{2}'}') \frac{\partial \sigma_{t_{1}'}}{\partial S_{t_{1}''t_{2}''}}\right)\\&=\frac{1}{\sigma_{t_{1}'}^2}\left(\exp(S_{t_{1}'t_{2}'}')\delta_{t_{1}'t_{1}''}\delta_{t_{2}'t_{2}''}\sigma_{t_{1}'}-\exp(S_{t_{1}'t_{2}'}')\exp(S'_{t_{1}'t_{2}''})\delta_{t_{1}'t_{1}''}\right)\\&=\delta_{t_{1}'t_{1}''}\left(A_{t_1' t_2'}\delta_{t_{2}'t_{2}''}-A_{t_1' t_2'}A_{t_1' t_2''}\right)\end{aligned}$$
</li>
<li>
<p>ä»£å› (1) å’Œ (2) åˆ°å±€éƒ¨æ¢¯åº¦ï¼š</p>
$$\frac{\partial A_{t_1' t_2'}}{\partial S_{t_1 t_2}} =  A_{t_1' t_2'} (\delta_{t_2' t_2} - A_{t_1' t_2})  \left( \frac{1}{\sqrt{d_{out}}} \delta_{t_1' t_1} \right)$$
</li>
</ol>
</li>
<li>
<p>ä»£å› $G^S$ çš„æ¨å¯¼ï¼š</p>
$$G^S_{t_1 t_2} = G^A_{t_1' t_2'} A_{t_1' t_2'} (\delta_{t_2' t_2} - A_{t_1' t_2})  \left( \frac{1}{\sqrt{d_{out}}} \delta_{t_1' t_1} \right)$$
$$G^S_{t_1 t_2} = \frac{1}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2'} A_{t_1 t_2'} \delta_{t_2' t_2} - G^A_{t_1 t_2'} A_{t_1 t_2'} A_{t_1 t_2} \right)$$
$$G^S_{t_1 t_2} = \frac{1}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} A_{t_1 t_2} - A_{t_1 t_2}G^A_{t_1 t_2'} A_{t_1 t_2'} \right)$$
$$G^S_{t_1 t_2} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} - G^A_{t_1 t_2'} A_{t_1 t_2'} \right)$$
<p>(å…¶ä¸­ $t_2'$ æ˜¯åœ¨ $G^A$ å’Œ $A$ çš„é€å…ƒç´ ä¹˜ç§¯ä¸Šæ±‚å’Œçš„å“‘ç´¢å¼•ã€‚)</p>
</li>
</ul>
<p><strong>æ­¥éª¤ 2.3ï¼šè®¡ç®— $\frac{\partial L}{\partial Q}$ (å³ $G^Q$)</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š (ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ $G^S$ ä½œä¸ºä¸Šæ¸¸æ¢¯åº¦)</p>
$$G^Q_{t_1 j} = \frac{\partial L}{\partial Q_{t_1 j}} = \frac{\partial L}{\partial S_{t_1' t_2'}} \frac{\partial S_{t_1' t_2'}}{\partial Q_{t_1 j}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial S_{t_1' t_2'}}{\partial Q_{t_1 j}} = \frac{\partial (Q_{t_1' j'} K_{t_2' j'})}{\partial Q_{t_1 j}} = \delta_{t_1' t_1} K_{t_2' j}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$G^Q_{t_1 j} = G^S_{t_1 t_2} K_{t_2 j}$$
</li>
</ul>
<p><strong>æ­¥éª¤ 2.4ï¼šè®¡ç®— $\frac{\partial L}{\partial K}$ (å³ $G^K$)</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $S_{t_1 t_2} = Q_{t_1 j} K_{t_2 j}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
$$G^K_{t_2 j} = \frac{\partial L}{\partial K_{t_2 j}} = \frac{\partial L}{\partial S_{t_1' t_2'}} \frac{\partial S_{t_1' t_2'}}{\partial K_{t_2 j}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial S_{t_1' t_2'}}{\partial K_{t_2 j}} = \frac{\partial (Q_{t_1' j'} K_{t_2' j'})}{\partial K_{t_2 j}} = Q_{t_1' j} \delta_{t_2' t_2}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$G^K_{t_2 j} = G^S_{t_1 t_2} Q_{t_1 j}$$
</li>
</ul>
<p><strong>æ­¥éª¤ 2.5ï¼šè®¡ç®— $\frac{\partial L}{\partial W^Q}$</strong></p>
<ul>
<li>
<p><strong>å‰å‘æ–¹ç¨‹ï¼š</strong> $Q_{t_1 j} = X_{t_1 i} W^Q_{ji}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
$$\frac{\partial L}{\partial W^Q_{ji}} = \frac{\partial L}{\partial Q_{t_1' j'}} \frac{\partial Q_{t_1' j'}}{\partial W^Q_{ji}}$$
</li>
<li>
<p><strong>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š</strong> $\frac{\partial Q_{t_1' j'}}{\partial W^Q_{ji}} = \frac{\partial (X_{t_1' i'} W^Q_{j' i'})}{\partial W^Q_{ji}} = X_{t_1' i} \delta_{j' j}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$\frac{\partial L}{\partial W^Q_{ji}} = G^Q_{t_1 j} X_{t_1 i}$$
</li>
</ul>
<p><strong>æ­¥éª¤ 2.6ï¼šè®¡ç®— $\frac{\partial L}{\partial W^K}$</strong></p>
<ul>
<li>
<p>å‰å‘æ–¹ç¨‹ï¼š $K_{t_2 j} = X_{t_2 k} W^K_{jk}$</p>
</li>
<li>
<p>åº”ç”¨é“¾å¼æ³•åˆ™ï¼š</p>
$$\frac{\partial L}{\partial W^K_{jk}} =  \frac{\partial L}{\partial K_{t_2' j'}} \frac{\partial K_{t_2' j'}}{\partial W^K_{jk}}$$
</li>
<li>
<p>è®¡ç®—å±€éƒ¨æ¢¯åº¦ï¼š $\frac{\partial K_{t_2' j'}}{\partial W^K_{jk}} = \frac{\partial (X_{t_2' k'} W^K_{j' k'})}{\partial W^K_{jk}} = X_{t_2' k} \delta_{j' j}$</p>
</li>
<li>
<p>ä»£å›ï¼ˆå¹¶ä½¿ç”¨çˆ±å› æ–¯å¦çº¦å®šï¼‰ï¼š</p>
$$\frac{\partial L}{\partial W^K_{jk}} = G^K_{t_2 j} X_{t_2 k}$$
</li>
</ul>
<p><strong>$W^Q$ å’Œ $W^K$ æ¢¯åº¦æ€»ç»“</strong></p>
<p>å°† <strong>2.3</strong> ä»£å…¥ <strong>2.5</strong>ï¼Œå¾—åˆ° $W^Q$ çš„æœ€ç»ˆæ¢¯åº¦ï¼š</p>
$$\frac{\partial L}{\partial W^Q_{ji}} = (G^S_{t_1 t_2} K_{t_2 j}) X_{t_1 i}$$
<p>å°† <strong>2.4</strong> ä»£å…¥ <strong>2.6</strong>ï¼Œå¾—åˆ° $W^K$ çš„æœ€ç»ˆæ¢¯åº¦ï¼š</p>
$$\frac{\partial L}{\partial W^K_{jk}} = (G^S_{t_1 t_2} Q_{t_1 j}) X_{t_2 k}$$
<p>å…¶ä¸­ $G^S_{t_1 t_2}$ ç”±<strong>æ­¥éª¤ 2.2</strong> å®šä¹‰, å¦‚ä¸‹æ‰€ç¤ºï¼š
</p>
$$
G^S_{t_1 t_2} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( G^A_{t_1 t_2} - G^A_{t_1 t_2'} A_{t_1 t_2'} \right)
$$
<hr>
<h4 id="ç¬¬3éƒ¨åˆ†æ•°æ®æ¢¯åº¦çš„æ¨å¯¼">ç¬¬3éƒ¨åˆ†ï¼šæ•°æ®æ¢¯åº¦çš„æ¨å¯¼
</h4><hr>
<h3 id="æœ€ç»ˆæ¢¯åº¦æ€»ç»“">æœ€ç»ˆæ¢¯åº¦æ€»ç»“
</h3><p>ä»¥ä¸‹æ˜¯æŸå¤± $L$ å¯¹ä¸‰ä¸ªæƒé‡çŸ©é˜µçš„å®Œæ•´æ¢¯åº¦ï¼Œå…¶ä¸­ $G^S$ å·²è¢«æ˜ç¡®æ¨å¯¼ã€‚</p>
<ol>
<li>
<p>Value æƒé‡æ¢¯åº¦ ($W^V$):</p>
$$\frac{\partial L}{\partial W^V_{jk}} = \left( \frac{\partial L}{\partial Y_{t_1 j}} A_{t_1 t_2} \right) X_{t_2 k}$$
</li>
</ol>
<blockquote>
<p>å…¬å¼è§£é‡Šï¼šValue æƒé‡æ¢¯åº¦æ˜¯è¯¯å·®ä¿¡å·å’Œæ³¨æ„åŠ›æƒé‡åœ¨ $t_{1}$ ä¸Šçš„å†…ç§¯ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—Valueåœ¨æŸ¥è¯¢tokenç»´åº¦ä¸Šå¯¹è¯¯å·®ä¿¡å·æœ‰å¤šå¤§è´¡çŒ®ï¼Œå³åˆ†é…ç»™Valueçš„è¯¯å·®ã€‚ç„¶åå†å’Œè¾“å…¥åµŒå…¥åœ¨ $t_{2}$ ä¸Šçš„å†…ç§¯ï¼Œè®¡ç®—æ­¤æ—¶è¢« $X_{t_{2}k}$ æ¿€æ´»çš„ä¿¡å·ã€‚</p>
</blockquote>
<ol>
<li>
<p>Query æƒé‡æ¢¯åº¦ ($W^Q$):</p>
$$\frac{\partial L}{\partial W^Q_{ji}} = \left( \frac{\partial L}{\partial S_{t_1 t_2}} K_{t_2 j} \right) X_{t_1 i}$$
<p>
å…¬å¼è§£é‡Šï¼š</p>
</li>
<li>
<p>Key æƒé‡æ¢¯åº¦ ($W^K$):</p>
$$\frac{\partial L}{\partial W^K_{jk}} = \left( \frac{\partial L}{\partial S_{t_1 t_2}} Q_{t_1 j} \right) X_{t_2 k}$$
</li>
</ol>
<p>å…¶ä¸­ï¼Œå…³é”®çš„ä¸­é—´æ¢¯åº¦ $\frac{\partial L}{\partial S_{t_1 t_2}}$ (å³ $G^S$) å®šä¹‰ä¸ºï¼š</p>
$$\frac{\partial L}{\partial S_{t_1 t_2}} = \frac{A_{t_1 t_2}}{\sqrt{d_{out}}} \left( \frac{\partial L}{\partial A_{t_1 t_2}} - \sum_{t_2'} \frac{\partial L}{\partial A_{t_1 t_2'}} A_{t_1 t_2'} \right)$$
<blockquote>
<p>å…¬å¼è§£é‡Š: æ³¨æ„åŠ›æƒé‡å¯¹æŸå¤±çš„è´¡çŒ®æ—¢è¦çœ‹ç›´æ¥è´¡çŒ®ä¹Ÿè¦çœ‹å¹³å‡è´¡çŒ®ã€‚æ‹¬å·å†…çš„æ±‚å’Œå®é™…ä¸Šå°±æ˜¯æ±‚å¹³å‡è´¡çŒ®ï¼Œæ˜¯ä¸€ä¸ªç›¸å¯¹æ ‡å‡†ï¼Œå®ƒå¥–åŠ±é‚£äº›è¡¨ç°åç¦»â€œå¹³å‡æ°´å¹³â€çš„å¾—åˆ†ï¼Œå¹¶æƒ©ç½šé‚£äº›è¡¨ç°ä¸å¦‚å¹³å‡æ°´å¹³çš„å¾—åˆ†ã€‚</p>
</blockquote>
<p>è€Œ $\frac{\partial L}{\partial A_{t_1 t_2}}$ (å³ $G^A$) å®šä¹‰ä¸ºï¼š</p>
$$\frac{\partial L}{\partial A_{t_1 t_2}} = \frac{\partial L}{\partial Y_{t_1 j}} V_{t_2 j}$$
<h3 id="æ¢¯åº¦å…¬å¼çš„pytorchéªŒè¯">æ¢¯åº¦å…¬å¼çš„pytorchéªŒè¯
</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.testing</span> <span class="c1"># å¯¼å…¥æµ‹è¯•åº“</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># æ­¥éª¤ 1: ä¿®æ”¹ SelfAttention ä»¥å­˜å‚¨ q, k, v</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># æˆ‘ä»¬å¿…é¡»å­˜å‚¨ q, k, v æ‰èƒ½åœ¨ä¹‹åè®¿é—®å®ƒä»¬æ¥è®¡ç®—æ¢¯åº¦</span>
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># ä¸ºæ‰€æœ‰ä¸­é—´å¼ é‡æ·»åŠ å ä½ç¬¦</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">attn_scores</span> <span class="o">=</span> <span class="kc">None</span> Â <span class="c1"># S</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">attn_weights</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># A</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">context_vecs</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Y</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Â  Â  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># è®¡ç®— q, k, v å¹¶ *ä¿å­˜* å®ƒä»¬</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># d_k (d_out) çš„ç¼©æ”¾å› å­</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># S = Q @ K.T</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">attn_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># A = softmax(S / scale)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_scores</span> <span class="o">/</span> <span class="n">scale</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="c1"># Y = A @ V</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="bp">self</span><span class="o">.</span><span class="n">context_vecs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_vecs</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># æ­¥éª¤ 2: è®¾ç½®å¹¶è¿è¡Œå‰å‘å’Œåå‘ä¼ æ’­</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># è®¾ç½®è¾“å…¥ç»´åº¦å’Œè¾“å‡ºç»´åº¦</span>
</span></span><span class="line"><span class="cl"><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="c1"># åˆ›å»ºSelfAttentionå¯¹è±¡</span>
</span></span><span class="line"><span class="cl"><span class="n">attention</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">j</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ä¸ºäº†å¯å¤ç°æ€§ï¼Œå›ºå®šéšæœºç§å­</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># åˆ›å»ºè¾“å…¥å¼ é‡å’Œä¸Šæ¸¸æ¢¯åº¦</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># (B, S_in, d_in)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span> <span class="c1"># (B, S_out, d_out)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># è¿è¡Œå‰å‘å’Œåå‘è¿‡ç¨‹</span>
</span></span><span class="line"><span class="cl"><span class="c1"># è¿™ä¼šä¸º W_v.weight, W_q.weight, W_k.weight è‡ªåŠ¨å¡«å…… .grad å±æ€§</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">y_grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># æ­¥éª¤ 3: æŒ‰ç…§ä½ æä¾›çš„å…¬å¼æ‰‹åŠ¨è®¡ç®—æ¢¯åº¦å¹¶è¿›è¡ŒéªŒè¯</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;--- æ¢¯åº¦éªŒè¯å¼€å§‹ ---&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ç´¢å¼•çº¦å®š:</span>
</span></span><span class="line"><span class="cl"><span class="c1"># b: batch (10)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># q: query token åºåˆ— (10)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># v: key/value token åºåˆ— (10)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># i: d_in (10)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># o: d_out (20)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 3.A: è®¡ç®—ä¸­é—´æ¢¯åº¦ G^A å’Œ G^S</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># G^A = dL/dA</span>
</span></span><span class="line"><span class="cl"><span class="c1"># å…¬å¼: dL/dA[q,v] = dL/dY[q,o] * V[v,o]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># einsum: (bqo, bvo) -&gt; bqv</span>
</span></span><span class="line"><span class="cl"><span class="n">grad_A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bqo, bvo -&gt; bqv&#39;</span><span class="p">,</span> <span class="n">y_grad</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># G^S = dL/dS</span>
</span></span><span class="line"><span class="cl"><span class="c1"># è¿™æ˜¯ softmax çš„åå‘ä¼ æ’­</span>
</span></span><span class="line"><span class="cl"><span class="c1"># å…¬å¼: dL/dS = (A / scale) * (dL/dA - sum(dL/dA * A))</span>
</span></span><span class="line"><span class="cl"><span class="n">scale</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">attn_weights</span>
</span></span><span class="line"><span class="cl"><span class="c1"># sum(dL/dA * A)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># einsum: (bqv, bqv) -&gt; bq</span>
</span></span><span class="line"><span class="cl"><span class="n">row_dot_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bqv, bqv -&gt; bq&#39;</span><span class="p">,</span> <span class="n">grad_A</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># å½¢çŠ¶å˜ä¸º (b,q,1)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># dL/dS&#39; = A * (dL/dA - sum(dL/dA * A))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (bqv) * ((bqv) - (bq,1)) -&gt; (bqv)</span>
</span></span><span class="line"><span class="cl"><span class="n">grad_S_prime</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="p">(</span><span class="n">grad_A</span> <span class="o">-</span> <span class="n">row_dot_sum</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># dL/dS = dL/dS&#39; / scale</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (bqv)</span>
</span></span><span class="line"><span class="cl"><span class="n">grad_S</span> <span class="o">=</span> <span class="n">grad_S_prime</span> <span class="o">/</span> <span class="n">scale</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 3.B: éªŒè¯ Value æƒé‡æ¢¯åº¦ (W^V)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># å…¬å¼: dL/dW_v[o,i] = (dL/dY[q,o] * A[q,v]) * X[v,i]</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># (æ³¨æ„ä½ çš„å…¬å¼ä¸­ j-&gt;o, k-&gt;i, t1-&gt;q, t2-&gt;v)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># einsum: (bqo, bqv, bvi) -&gt; oi</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">grad_Wv_manual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bqo, bqv, bvi -&gt; oi&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">y_grad</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">attention</span><span class="o">.</span><span class="n">attn_weights</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">grad_Wv_manual</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">W_v</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;W_v æ¢¯åº¦è®¡ç®—æ­£ç¡®&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;W_v æ¢¯åº¦è®¡ç®—é”™è¯¯:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 3.C: éªŒè¯ Query æƒé‡æ¢¯åº¦ (W^Q)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># å…¬å¼: dL/dW_q[o,i] = (dL/dS[q,v] * K[v,o]) * X[q,i]</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># (æ³¨æ„ä½ çš„å…¬å¼ä¸­ j-&gt;o, i-&gt;i, t1-&gt;q, t2-&gt;v)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># einsum: (bqv, bvo, bqi) -&gt; oi</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">grad_Wq_manual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bqv, bvo, bqi -&gt; oi&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">grad_S</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">attention</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">grad_Wq_manual</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">W_q</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;W_q æ¢¯åº¦è®¡ç®—æ­£ç¡®&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;W_q æ¢¯åº¦è®¡ç®—é”™è¯¯:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 3.D: éªŒè¯ Key æƒé‡æ¢¯åº¦ (W^K)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ---------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># å…¬å¼: dL/dW_k[o,i] = (dL/dS[q,v] * Q[q,o]) * X[v,i]</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># (æ³¨æ„ä½ çš„å…¬å¼ä¸­ j-&gt;o, k-&gt;i, t1-&gt;q, t2-&gt;v)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="c1"># einsum: (bqv, bqo, bvi) -&gt; oi</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">grad_Wk_manual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bqv, bqo, bvi -&gt; oi&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">grad_S</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">attention</span><span class="o">.</span><span class="n">q</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span><span class="p">(</span><span class="n">grad_Wk_manual</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">W_k</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;W_k æ¢¯åº¦è®¡ç®—æ­£ç¡®&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">Â  Â  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;W_k æ¢¯åº¦è®¡ç®—é”™è¯¯:</span><span class="se">\n</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;--- æ¢¯åº¦éªŒè¯å®Œæˆ ---&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="å¤šå¤´æ³¨æ„åŠ›">å¤šå¤´æ³¨æ„åŠ›
</h2><p>ä»£ç éƒ¨åˆ†</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiHeadSelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span> <span class="c1"># input dimension</span>
</span></span><span class="line"><span class="cl">	<span class="n">dim_k</span><span class="p">:</span> <span class="nb">int</span> <span class="c1"># key and query dimension</span>
</span></span><span class="line"><span class="cl">	<span class="n">dim_v</span><span class="p">:</span> <span class="nb">int</span> <span class="c1"># value dimension</span>
</span></span><span class="line"><span class="cl">	<span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="c1"># number of heads, for each head, dim_* = dim_* // num_heads</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_k</span><span class="p">,</span> <span class="n">dim_v</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadSelfAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">	<span class="k">assert</span> <span class="n">dim_k</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">dim_v</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&#34;dim_k and dim_v must be multiple of num_heads&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">dim_in</span> <span class="o">=</span> <span class="n">dim_in</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">dim_k</span> <span class="o">=</span> <span class="n">dim_k</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">dim_v</span> <span class="o">=</span> <span class="n">dim_v</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">linear_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">linear_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_k</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">linear_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_v</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="bp">self</span><span class="o">.</span><span class="n">_norm_fact</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">dim_k</span> <span class="o">//</span> <span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl"><span class="c1"># x: tensor of shape (batch, n, dim_in)</span>
</span></span><span class="line"><span class="cl">	<span class="n">batch</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">dim_in</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">	<span class="k">assert</span> <span class="n">dim_in</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_in</span>
</span></span><span class="line"><span class="cl">	<span class="n">nh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
</span></span><span class="line"><span class="cl">	<span class="n">dk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_k</span> <span class="o">//</span> <span class="n">nh</span> <span class="c1"># dim_k of each head</span>
</span></span><span class="line"><span class="cl">	<span class="n">dv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_v</span> <span class="o">//</span> <span class="n">nh</span> <span class="c1"># dim_v of each head</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">dk</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (batch, nh, n, dk)</span>
</span></span><span class="line"><span class="cl">	<span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">dk</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (batch, nh, n, dk)</span>
</span></span><span class="line"><span class="cl">	<span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">dv</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (batch, nh, n, dv)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_norm_fact</span> <span class="c1"># batch, nh, n, n</span>
</span></span><span class="line"><span class="cl">	<span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># batch, nh, n, n</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">att</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="c1"># batch, nh, n, dv</span>
</span></span><span class="line"><span class="cl">	<span class="n">att</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim_v</span><span class="p">)</span> <span class="c1"># batch, n, dim_v</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">att</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>è¿™æ­£æ˜¯<strong>å¤šå¤´è‡ªæ³¨æ„åŠ› (Multi-Head Self-Attention, MHSA)</strong> çš„ä¸€ä¸ªé«˜æ•ˆå®ç°ã€‚</p>
<p>ä¸å•å¤´è‡ªæ³¨æ„åŠ›ä¸€æ ·ï¼Œ<code>softmax</code> çš„å­˜åœ¨ä½¿å…¶æˆä¸ºä¸€ä¸ª<strong>éçº¿æ€§</strong>æ“ä½œï¼Œå› æ­¤æˆ‘ä»¬ä¸èƒ½å°†å…¶è¡¨ç¤ºä¸º<strong>å•ä¸€çš„</strong>é™æ€å¼ é‡ç¼©å¹¶ã€‚</p>
<p>ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥å°†ä»£ç ä¸­çš„æ¯ä¸€æ­¥â€”â€”ç‰¹åˆ«æ˜¯ <code>reshape</code> å’Œ <code>transpose</code> æ“ä½œâ€”â€”ç”¨æ›´æ¸…æ™°çš„çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š (Einstein Summation Convention) æ¥è¡¨ç¤ºã€‚</p>
<p><strong>ç´¢å¼•å’Œå¼ é‡å®šä¹‰</strong>
æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ–°çš„ç´¢å¼• <code>h</code> æ¥ä»£è¡¨<strong>æ³¨æ„åŠ›å¤´ (Head)</strong>ã€‚</p>
<ul>
<li>$b$: Batch (æ‰¹æ¬¡) ç´¢å¼•</li>
<li>$t_1, t_2$: Token/åºåˆ— (Sequence) ç´¢å¼• (åŸºæ•°éƒ½ä¸º $n$)</li>
<li>$i, k$: è¾“å…¥ç‰¹å¾ç»´åº¦ ($dim\_in$) çš„ç´¢å¼•</li>
<li>$h$: æ³¨æ„åŠ›å¤´ç´¢å¼• (åŸºæ•° <code>num_heads</code>)</li>
<li>$j$: é”®/æŸ¥è¯¢ (Key/Query) ç‰¹å¾ç»´åº¦ (åŸºæ•° <code>dk = dim_k // num_heads</code>)</li>
<li>$m$: å€¼ (Value) ç‰¹å¾ç»´åº¦ (åŸºæ•° <code>dv = dim_v // num_heads</code>)</li>
</ul>
<p><strong>è¾“å…¥å¼ é‡ï¼š</strong></p>
<ul>
<li><strong>Input $X$:</strong> $X_{bti}$ (å¯¹åº” <code>x</code>)</li>
</ul>
<p>æƒé‡å¼ é‡ (é€»è¾‘ä¸Šçš„)ï¼š
ä»£ç ä¸­çš„ nn.Linear(dim_in, dim_k) åªæ˜¯ä¸€ä¸ªè®¡ç®—ä¸Šçš„èåˆã€‚åœ¨é€»è¾‘ä¸Šï¼Œå®ƒä»£è¡¨äº† num_heads ä¸ªç‹¬ç«‹çš„æƒé‡çŸ©é˜µã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æƒé‡å¼ é‡å®šä¹‰ä¸ºï¼š</p>
<ul>
<li><strong>Query Weights $W_Q$:</strong> $W^Q_{hji}$ (å½¢çŠ¶ <code>nh, dk, dim_in</code>)</li>
<li><strong>Key Weights $W_K$:</strong> $W^K_{hji}$ (å½¢çŠ¶ <code>nh, dk, dim_in</code>)</li>
<li><strong>Value Weights $W_V$:</strong> $W^V_{hmi}$ (å½¢çŠ¶ <code>nh, dv, dim_in</code>)
(æ³¨ï¼šä»£ç ä¸­ <code>self.linear_q.weight</code> çš„å®é™…å½¢çŠ¶æ˜¯ <code>(dim_k, dim_in)</code>ï¼Œå³ <code>(nh*dk, dim_in)</code>ã€‚$W^Q_{hji}$ æ˜¯å®ƒåœ¨é€»è¾‘ä¸Šçš„ <code>(nh, dk, dim_in)</code> é‡å¡‘ã€‚)</li>
</ul>
<hr>
<p><strong>å¼ é‡åŒ–æ­¥éª¤</strong></p>
<ol>
<li>q, k, v çš„è®¡ç®— (çº¿æ€§)
ä»£ç ä¸­çš„ linear_q(x).reshape(&hellip;).transpose(&hellip;) è¿™ä¸€æ•´è¡Œæ“ä½œï¼Œåœ¨å¼ é‡è¡¨ç¤ºæ³•ä¸­åªæ˜¯ä¸€ä¸ªå•ç‹¬çš„ã€ç®€æ´çš„å¼ é‡ç¼©å¹¶ï¼š
<ul>
<li><strong>Query:</strong> $Q_{bht_1 j} = X_{bt_1 i} W^Q_{hji}$</li>
<li><strong>Key:</strong> $K_{bht_2 j} = X_{bt_2 i} W^K_{hji}$</li>
<li><strong>Value:</strong> $V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$
<em>åˆ†æï¼š</em> ä»¥ $Q$ ä¸ºä¾‹ï¼Œ $X$ (<code>b, t1, i</code>) å’Œ $W^Q$ (<code>h, j, i</code>) åœ¨ <code>i</code> ç»´åº¦ä¸Šç¼©å¹¶ï¼Œè‡ªç”±ç´¢å¼• $b, h, t_1, j$ ä¿ç•™ä¸‹æ¥ï¼Œæ­£å¥½å¾—åˆ°ä»£ç ä¸­ $q$ çš„å½¢çŠ¶ <code>(batch, nh, n, dk)</code>ã€‚<code>reshape</code> å’Œ <code>transpose</code> åªæ˜¯ PyTorch å®ç°è¿™ä¸€é€»è¾‘æ‰€å¿…éœ€çš„æ­¥éª¤ã€‚</li>
</ul>
</li>
<li>dist çš„è®¡ç®— (çº¿æ€§éƒ¨åˆ†)
è¿™æ˜¯ $Q$ å’Œ $K$ çš„æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œåœ¨ $j$ (å³ dk) ç»´åº¦ä¸Šç¼©å¹¶ï¼š
<ul>
<li><strong>Scores:</strong> $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$</li>
<li><strong>Scaled Scores:</strong> $S'_{bht_1 t_2} = \frac{S_{bht_1 t_2}}{\sqrt{d_k}}$ (å…¶ä¸­ $d_k$ = <code>dk</code>)</li>
</ul>
</li>
<li>dist çš„è®¡ç®— (éçº¿æ€§)
softmax æ²¿ç€ $t_2$ ç»´åº¦ï¼ˆä»£ç ä¸­çš„ dim=-1ï¼‰è¿›è¡Œï¼š
<ul>
<li><strong>Weights:</strong> $A_{bht_1 t_2} = \text{softmax}_{t_2}(S'_{bht_1 t_2})$</li>
</ul>
</li>
<li>att çš„è®¡ç®— (çº¿æ€§)
è¿™æ˜¯æ³¨æ„åŠ›æƒé‡ $A$ å’Œå€¼ $V$ çš„æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œåœ¨ $t_2$ ç»´åº¦ä¸Šç¼©å¹¶ï¼š
<ul>
<li><strong>Head Context:</strong> $Y'_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$
<em>åˆ†æï¼š</em> æ­¤æ—¶æˆ‘ä»¬å¾—åˆ°çš„å¼ é‡ $Y'$ å½¢çŠ¶ä¸º <code>(batch, nh, n, dv)</code>ï¼Œå¯¹åº”ä»£ç ä¸­ <code>matmul(dist, v)</code> çš„ç›´æ¥è¾“å‡ºã€‚</li>
</ul>
</li>
<li>att çš„é‡å¡‘ (Concat)
ä»£ç ä¸­çš„æœ€åä¸€æ­¥ att.transpose(1, 2).reshape(batch, n, self.dim_v) æ˜¯å°†æ‰€æœ‰å¤´çš„ä¸Šä¸‹æ–‡å‘é‡æ‹¼æ¥ (concatenate) èµ·æ¥ã€‚
åœ¨å¼ é‡è¡¨ç¤ºæ³•ä¸­ï¼Œè¿™æ˜¯å°† <code>h</code> (å¤´) å’Œ <code>m</code> (dv) ä¸¤ä¸ªç»´åº¦â€œå‹å¹³â€æˆä¸€ä¸ªå•ä¸€çš„ $dim\_v$ ç»´åº¦ã€‚å¦‚æœ $Y_{bt_1 l}$ æ˜¯æœ€ç»ˆè¾“å‡º (å…¶ä¸­ $l$ æ˜¯ $dim\_v$ ç´¢å¼•)ï¼Œé‚£ä¹ˆï¼š
<ul>
<li><strong>Final Output:</strong> $Y_{bt_1 l} = Y'_{bht_1 m}$ (å…¶ä¸­ $l = h \cdot d_v + m$)
è¿™åœ¨å¼ é‡è¡¨ç¤ºä¸­é€šå¸¸è¢«ç†è§£ä¸ºç»´åº¦çš„é‡å¡‘ï¼Œå³ $Y'_{bht_1 m}$ (å½¢çŠ¶ <code>b, h, t1, m</code>) è¢«é‡å¡‘ä¸º $Y_{bt_1 (hm)}$ (å½¢çŠ¶ <code>b, t1, [h*m]</code>)ã€‚</li>
</ul>
</li>
</ol>
<hr>
<p><strong>æ€»ç»“ï¼šç»„åˆçš„å¼ é‡å½¢å¼</strong>
æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ­¥éª¤ï¼ˆé™¤ <code>softmax</code> å¤–ï¼‰ä»£å…¥ï¼Œå¾—åˆ°ä¸€ä¸ªæ›´å®Œæ•´çš„è§†å›¾ï¼š</p>
<ol>
<li>è®¡ç®—åˆ†æ•° (Scores):
$$S'_{bht_1 t_2} = \frac{(X_{bt_1 i} W^Q_{hji}) (X_{bt_2 k} W^K_{hjk})}{\sqrt{d_k}}$$
(è¿™é‡Œæˆ‘ä»¬ç”¨ $i$ å’Œ $k$ ä½œä¸º dim_in çš„å“‘ç´¢å¼•ä»¥ç¤ºåŒºåˆ†)</li>
<li>åº”ç”¨éçº¿æ€§ (Softmax):
$$A_{bht_1 t_2} = \text{softmax}_{t_2}(S'_{bht_1 t_2})$$</li>
<li>è®¡ç®—å¤´éƒ¨ä¸Šä¸‹æ–‡ (Head Contexts):
$$Y'_{bht_1 m} = A_{bht_1 t_2} (X_{bt_2 i} W^V_{hmi})$$</li>
<li>æ‹¼æ¥å¤´éƒ¨ (Concatenate Heads):
$Y_{bt_1 l}$ (æœ€ç»ˆè¾“å‡º) æ˜¯ $Y'_{bht_1 m}$ å¼ é‡åœ¨ $h$ å’Œ $m$ ç»´åº¦ä¸Šçš„é‡å¡‘/æ‹¼æ¥ã€‚</li>
</ol>
<h3 id="æ¢¯åº¦æ¨å¯¼">æ¢¯åº¦æ¨å¯¼
</h3><p>æˆ‘ä»¬å°†ä½¿ç”¨åå‘ä¼ æ’­çš„é“¾å¼æ³•åˆ™ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ±‚å‡ºæ ‡é‡æŸå¤±å‡½æ•° $L$ ç›¸å¯¹äºä¸‰ä¸ªæƒé‡å¼ é‡ $W^Q$, $W^K$, $W^V$ çš„æ¢¯åº¦ã€‚</p>
<h3 id="1-ç¬¦å·çº¦å®š">1. ç¬¦å·çº¦å®š
</h3><ul>
<li><strong>æ ‡é‡æŸå¤± (Scalar Loss):</strong> $L$</li>
<li><strong>æ¢¯åº¦ç¬¦å·:</strong> $\bar{Z} = \frac{\partial L}{\partial Z}$ã€‚ä¾‹å¦‚ï¼Œ$\bar{W}^Q_{hji}$ æ˜¯ $L$ å¯¹ $W^Q_{hji}$ çš„æ¢¯åº¦ã€‚</li>
<li><strong>ç´¢å¼• (Indices):</strong> ä¸ä¸Šä¸€æ¡å›å¤ç›¸åŒï¼š
<ul>
<li>$b$: Batch, $t_1, t_2$: Token, $i$: $d_{in}$, $h$: Head</li>
<li>$j$: $d_k$ (K/Q dim), $m$: $d_v$ (V dim)</li>
</ul>
</li>
<li><strong>ç¼©æ”¾å› å­:</strong> $\alpha = 1 / \sqrt{d_k}$</li>
</ul>
<h3 id="2-å‰å‘ä¼ æ’­å›é¡¾">2. å‰å‘ä¼ æ’­ï¼ˆå›é¡¾ï¼‰
</h3><p>æˆ‘ä»¬éœ€è¦å‰å‘ä¼ æ’­çš„æ–¹ç¨‹æ¥è®¡ç®—åå‘ä¼ æ’­ï¼š</p>
<ol>
<li><strong>Q, K, V:</strong>
<ul>
<li>$Q_{bht_1 j} = X_{bt_1 i} W^Q_{hji}$</li>
<li>$K_{bht_2 j} = X_{bt_2 i} W^K_{hji}$</li>
<li>$V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$</li>
</ul>
</li>
<li><strong>Scores:</strong> $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$</li>
<li><strong>Scaled Scores:</strong> $S'_{bht_1 t_2} = S_{bht_1 t_2} \cdot \alpha$</li>
<li><strong>Weights:</strong> $A_{bht_1 t_2} = \text{softmax}_{t_2}(S'_{bht_1 t_2})$</li>
<li><strong>Head Context:</strong> $Y'_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$</li>
<li><strong>Final Output (Reshape):</strong> $Y_{bt_1 l} = \text{Reshape}(Y'_{bht_1 m})$ (å…¶ä¸­ $l$ æ˜¯ $h$ å’Œ $m$ çš„ç»„åˆ)</li>
</ol>
<h3 id="3-åå‘ä¼ æ’­æ¢¯åº¦è®¡ç®—">3. åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦è®¡ç®—ï¼‰
</h3><p>æˆ‘ä»¬å‡è®¾æˆ‘ä»¬å·²ç»æ”¶åˆ°äº†æ¥è‡ªæ¨¡å‹åç»­å±‚æˆ–æŸå¤±å‡½æ•°çš„<strong>ä¸Šæ¸¸æ¢¯åº¦</strong>ï¼Œå³ $\bar{Y}_{bt_1 l}$ã€‚
<strong>æ­¥éª¤ 0ï¼šæ¢¯åº¦çš„ &ldquo;Un-Reshape&rdquo;</strong>
é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†ä¸Šæ¸¸æ¢¯åº¦ $\bar{Y}_{bt_1 l}$ æ¢å¤åˆ°æ‹¼æ¥ (concatenate) ä¹‹å‰çš„å½¢çŠ¶ï¼š</p>
<ul>
<li>$\bar{Y}'_{bht_1 m} = \text{Un-Reshape}(\bar{Y}_{bt_1 l})$
ç°åœ¨æˆ‘ä»¬æœ‰äº† $\bar{Y}'_{bht_1 m}$ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®¡ç®—ã€‚</li>
</ul>
<hr>
<h4 id="a-barwv-value-æƒé‡çš„æ¢¯åº¦">A. $\bar{W}^V$ (Value æƒé‡çš„æ¢¯åº¦)
</h4><p>è¿™æ˜¯æœ€ç®€å•çš„è·¯å¾„ï¼Œå› ä¸ºå®ƒä¸ç»è¿‡ softmaxã€‚</p>
<p>æ­¥éª¤ A1ï¼šè®¡ç®— $\bar{A}$ å’Œ $\bar{V}$</p>
<p>æˆ‘ä»¬ä» $Y'_{bht_1 m} = A_{bht_1 t_2} V_{bht_2 m}$ å¼€å§‹ï¼Œå¯¹ $A$ å’Œ $V$ æ±‚åå¯¼ï¼š</p>
<ul>
<li>
<p><strong>$\bar{A}_{bht_1 t_2}$</strong> (å¯¹ $A$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{A}_{bht_1 t_2} = \bar{Y}'_{bht_1 m} V_{bht_2 m}$</li>
</ul>
</li>
<li>
<p><strong>$\bar{V}_{bht_2 m}$</strong> (å¯¹ $V$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{V}_{bht_2 m} = A_{bht_1 t_2} \bar{Y}'_{bht_1 m}$</li>
</ul>
</li>
</ul>
<p>æ­¥éª¤ A2ï¼šè®¡ç®— $\bar{W}^V$</p>
<p>æˆ‘ä»¬ä» $V_{bht_2 m} = X_{bt_2 i} W^V_{hmi}$ å’Œ $\bar{V}_{bht_2 m}$ å¼€å§‹ï¼š</p>
<ul>
<li>
<p><strong>$\bar{W}^V_{hmi}$</strong> (å¯¹ $W^V$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{W}^V_{hmi} = \bar{V}_{bht_2 m} X_{bt_2 i}$</li>
</ul>
</li>
</ul>
<blockquote>
<p>$\bar{W}^V$ æœ€ç»ˆå…¬å¼:</p>
$$\bar{W}^V_{hmi} = (A_{bht_1 t_2} \bar{Y}'_{bht_1 m}) X_{bt_2 i}$$
<p>(å¯¹ $b, t_1, t_2$ æ±‚å’Œ)</p>
</blockquote>
<p>å…¬å¼è¯´æ˜ï¼šæŸå¤±å‡½æ•° $L$ å¯¹ $W^{V}$ çš„æ¢¯åº¦ã€‚è‡ªç”±æŒ‡æ ‡æ˜¯ $hmi$ ï¼Œè¯´æ˜æ¢¯åº¦ä¾èµ–ä¸åŒçš„æ³¨æ„åŠ›å¤´ã€å€¼åµŒå…¥ã€è¾“å…¥åµŒå…¥è¿›è¡ŒåŒºåˆ†ã€‚
$\bar{Y}'_{bht_1 m}$ ä¼ é€’äº†ä¸Šä¸€å±‚çš„è¯¯å·®ä¿¡å·ï¼ˆå‰å‘ä¼ æ’­çš„ä¸‹ä¸€å±‚ï¼‰ï¼Œ$A_{bht_1 t_2}$ æ˜¯æ³¨æ„åŠ›åˆ†æ•°ï¼Œ$X_{bt_2 i}$ æ˜¯å€¼æ•°æ®ã€‚å…ˆè®¡ç®—äº†è¯¯å·®ä¿¡å·å’Œæ³¨æ„åŠ›åˆ†æ•°åœ¨æŸ¥è¯¢tokenè§’åº¦çš„ç›¸ä¼¼ç¨‹åº¦ $\bar{V}_{bht_2 m}$ï¼Œä¹Ÿå°±æ˜¯åˆ†é…ç»™ $V_{bht_2 m}$ çš„<strong>è¯¯å·®æƒé‡</strong>ã€‚ç„¶åæ¯”è¾ƒäº†$\bar{V}_{bht_2 m}$ å’Œ $X_{bt_2 i}$ ä¹‹é—´åœ¨æ‰¹æ¬¡ã€å€¼tokenè§’åº¦ä¸Šçš„ç›¸ä¼¼åº¦</p>
<hr>
<h4 id="b-barwq-å’Œ-barwk-query-å’Œ-key-æƒé‡çš„æ¢¯åº¦">B. $\bar{W}^Q$ å’Œ $\bar{W}^K$ (Query å’Œ Key æƒé‡çš„æ¢¯åº¦)
</h4><p>è¿™æ¡è·¯å¾„æ›´é•¿ï¼Œå› ä¸ºå®ƒå¿…é¡»ç©¿è¿‡ $\bar{A}$ å’Œ softmaxã€‚</p>
<p>æ­¥éª¤ B1ï¼šè®¡ç®— $\bar{S}'$ (Softmax çš„æ¢¯åº¦)</p>
<p>è¿™æ˜¯æœ€å¤æ‚çš„ä¸€æ­¥ã€‚æˆ‘ä»¬éœ€è¦ $\bar{A}_{bht_1 t_2}$ (å·²åœ¨ A1 ä¸­æ±‚å¾—)ã€‚Softmax çš„å¯¼æ•°æ˜¯ä¸€ä¸ªé›…å¯æ¯”çŸ©é˜µï¼Œä½†åœ¨å¼ é‡è¡¨ç¤ºæ³•ä¸­ï¼Œå…¶åå‘ä¼ æ’­å¯ä»¥å†™ä¸ºï¼š</p>
<ul>
<li>
<p>é¦–å…ˆï¼Œè®¡ç®—æ¯è¡Œï¼ˆ$t_1$ï¼‰çš„â€œç‚¹ç§¯â€ï¼š$C_{bht_1} = \bar{A}_{bht_1 t_2} A_{bht_1 t_2}$</p>
</li>
<li>
<p>ç„¶åï¼Œ $\bar{S}'$ (å¯¹ $S'$ çš„æ¢¯åº¦) æ˜¯ï¼š</p>
<ul>
<li>$\bar{S}'_{bht_1 t_2} = A_{bht_1 t_2} (\bar{A}_{bht_1 t_2} - C_{bht_1})$</li>
</ul>
</li>
</ul>
<p>æ­¥éª¤ B2ï¼šè®¡ç®— $\bar{S}$ (ç¼©æ”¾çš„æ¢¯åº¦)</p>
<p>ä» $S'_{bht_1 t_2} = S_{bht_1 t_2} \cdot \alpha$ å¼€å§‹ï¼š</p>
<ul>
<li>$\bar{S}_{bht_1 t_2} = \bar{S}'_{bht_1 t_2} \cdot \alpha$</li>
</ul>
<p>æ­¥éª¤ B3ï¼šè®¡ç®— $\bar{Q}$ å’Œ $\bar{K}$</p>
<p>ä» $S_{bht_1 t_2} = Q_{bht_1 j} K_{bht_2 j}$ å’Œ $\bar{S}_{bht_1 t_2}$ å¼€å§‹ï¼š</p>
<ul>
<li>
<p><strong>$\bar{Q}_{bht_1 j}$</strong> (å¯¹ $Q$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{Q}_{bht_1 j} = \bar{S}_{bht_1 t_2} K_{bht_2 j}$</li>
</ul>
</li>
<li>
<p><strong>$\bar{K}_{bht_2 j}$</strong> (å¯¹ $K$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{K}_{bht_2 j} = \bar{S}_{bht_1 t_2} Q_{bht_1 j}$</li>
</ul>
</li>
</ul>
<p>æ­¥éª¤ B4ï¼šè®¡ç®— $\bar{W}^Q$ å’Œ $\bar{W}^K$</p>
<p>æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ $\bar{Q}$, $\bar{K}$ å’Œ $X$ï¼š</p>
<ul>
<li>
<p><strong>$\bar{W}^Q_{hji}$</strong> (å¯¹ $W^Q$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{W}^Q_{hji} = \bar{Q}_{bht_1 j} X_{bt_1 i}$</li>
</ul>
</li>
<li>
<p><strong>$\bar{W}^K_{hji}$</strong> (å¯¹ $W^K$ çš„æ¢¯åº¦):</p>
<ul>
<li>$\bar{W}^K_{hji} = \bar{K}_{bht_2 j} X_{bt_2 i}$</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-æ€»ç»“æœ€ç»ˆæ¢¯åº¦å…¬å¼">4. æ€»ç»“ï¼šæœ€ç»ˆæ¢¯åº¦å…¬å¼
</h3><p>å°†æ‰€æœ‰æ­¥éª¤ä»£å…¥ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸‰ä¸ªæƒé‡çŸ©é˜µçš„æœ€ç»ˆæ¢¯åº¦ï¼š</p>
<ol>
<li>
<p><strong>$\bar{W}^V_{hmi} = (A_{bht_1 t_2} \bar{Y}'_{bht_1 m}) X_{bt_2 i}$</strong></p>
</li>
<li>
<p><strong>$\bar{W}^Q_{hji} = ((\bar{S}'_{bht_1 t_2} \alpha) K_{bht_2 j}) X_{bt_1 i}$</strong></p>
</li>
<li>
<p><strong>$\bar{W}^K_{hji} = ((\bar{S}'_{bht_1 t_2} \alpha) Q_{bht_1 j}) X_{bt_2 i}$</strong></p>
</li>
</ol>
<p>å…¶ä¸­ $\bar{S}'_{bht_1 t_2}$ (æ¥è‡ª softmax çš„æ¢¯åº¦) æ˜¯ï¼š</p>
<p>$\bar{S}'_{bht_1 t_2} = A_{bht_1 t_2} \left( (\bar{Y}'_{bht_1 m} V_{bht_2 m}) - \sum_{t_2'} (\bar{Y}'_{bht_1 m} V_{bht_2' m}) A_{bht_1 t_2'} \right)$</p>
<p>(æ³¨ï¼šåœ¨æ‰€æœ‰å…¬å¼ä¸­ï¼Œé‡å¤çš„ç´¢å¼•éƒ½è¡¨ç¤ºæ±‚å’Œã€‚)</p>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 Soflari
    </section>
    
    <section class="powerby">
        ä½¿ç”¨ <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> æ„å»º <br />
        ä¸»é¢˜ <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.26.0">Stack</a></b> ç”± <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> è®¾è®¡
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/hugo_dev/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
